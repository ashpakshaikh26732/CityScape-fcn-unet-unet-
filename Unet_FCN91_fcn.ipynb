{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashpakshaikh26732/CityScape-fcn-unet-unet-/blob/main/Unet_FCN91_fcn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY-Fjqfj8lKQ",
        "outputId": "8f846b3c-ab7b-462c-abc7-2aeb5bb5ce49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XRgNljpyU9b"
      },
      "source": [
        "**all packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mm_LuZ1iev66"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from IPython.display import display,HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBI53Z14B58q",
        "outputId": "8b834dee-f920-4dbb-faa1-a7ebca44e22b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.18.0\n",
            "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow==2.18.0)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow==2.18.0)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow==2.18.0)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow==2.18.0)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.71.0)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow==2.18.0)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.13.0)\n",
            "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow==2.18.0)\n",
            "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.18.0)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow==2.18.0)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow==2.18.0)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow==2.18.0)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.18.0) (0.1.2)\n",
            "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m561.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, ml-dtypes, google-pasta, tensorboard, astunparse, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml_dtypes 0.5.1\n",
            "    Uninstalling ml_dtypes-0.5.1:\n",
            "      Successfully uninstalled ml_dtypes-0.5.1\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 ml-dtypes-0.4.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n",
            "Looking in links: https://storage.googleapis.com/libtpu-tf-releases/index.html\n",
            "Collecting tensorflow-tpu==2.18.0\n",
            "  Downloading tensorflow_tpu-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (0.4.1)\n",
            "Collecting libtpu==2.18.0 (from tensorflow-tpu==2.18.0)\n",
            "  Downloading https://storage.googleapis.com/libtpu-tf-releases/wheels/libtpu-2.18.0-py3-none-any.whl (123.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-tpu==2.18.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow-tpu==2.18.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-tpu==2.18.0) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-tpu==2.18.0) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-tpu==2.18.0) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-tpu==2.18.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-tpu==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-tpu==2.18.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow-tpu==2.18.0) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-tpu==2.18.0) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-tpu==2.18.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow-tpu==2.18.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-tpu==2.18.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow-tpu==2.18.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow-tpu==2.18.0) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-tpu==2.18.0) (0.1.2)\n",
            "Downloading tensorflow_tpu-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (234.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.3/234.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libtpu, tensorflow-tpu\n",
            "  Attempting uninstall: libtpu\n",
            "    Found existing installation: libtpu 0.0.7.1\n",
            "    Uninstalling libtpu-0.0.7.1:\n",
            "      Successfully uninstalled libtpu-0.0.7.1\n",
            "Successfully installed libtpu-2.18.0 tensorflow-tpu-2.18.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/jax/__init__.py:31: UserWarning: cloud_tpu_init failed: AttributeError(\"module 'libtpu' has no attribute 'get_library_path'\")\n",
            " This a JAX bug; please report an issue at https://github.com/jax-ml/jax/issues\n",
            "  _warn(f\"cloud_tpu_init failed: {exc!r}\\n This a JAX bug; please report \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU is running: \n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.18.0\n",
        "!pip install tensorflow-tpu==2.18.0 --find-links=https://storage.googleapis.com/libtpu-tf-releases/index.html\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    print(\"TPU is running:\", tpu.master())\n",
        "except ValueError as e:\n",
        "    print(\"TPU is not avaible:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-_0SdKWb53X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f46613-564c-41ec-afcc-1308fe425f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of TPUs: 8\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of TPUs: {strategy.num_replicas_in_sync}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTuYhVhRffta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e715307d-0eac-4a87-9dfe-95595052509b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "TPU failed to initialize: Please provide a TPU Name to connect to.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "print(f'TensorFlow version: {tf.__version__}')\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  print(f'TPU cluster resolved: {tpu.cluster_spec()}')\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.TPUStrategy(tpu)\n",
        "  print(f'Number of TPUs: {strategy.num_replicas_in_sync}')\n",
        "except Exception as e:\n",
        "  print(f'TPU failed to initialize: {e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzwsFyykuBp6"
      },
      "source": [
        "**mixed precision training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "I9g7HnQsuOMj",
        "outputId": "b7bd53b3-7db0-420d-b429-2cc6bb30afce"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1b3ffc459d08>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmixed_precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmixed_precision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_global_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mixed_float16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugzh9CWPo-zp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "cdN0drMo70q4",
        "outputId": "ff1f44fa-ce90-49ae-8eb4-c38364a137a7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b56b22cf7ffd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_functions_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ],
      "source": [
        "tf.config.run_functions_eagerly(False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQK2Gy1ggZP-",
        "outputId": "f0038cb8-318b-41fe-cd56-f6823dd8cee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLI9cZz46258"
      },
      "source": [
        "**copy datasets from drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cb4xI4h5b3z"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/cityscape/Cityscapes/gtFine_trainvaltest.zip /content/\n",
        "!cp /content/drive/MyDrive/cityscape/Cityscapes/leftImg8bit_trainvaltest.zip /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWcHvq9T67yT"
      },
      "source": [
        "**extract trainig the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIGN5YpV58XW",
        "outputId": "65a18c60-a4e5-4f16-bf26-6465e2e5ee3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "os.system(\"unzip -q /content/gtFine_trainvaltest.zip -d /content/ \")\n",
        "os.system(\"unzip -q /content/leftImg8bit_trainvaltest.zip -d /content/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MKUIQNX7naD",
        "outputId": "ade1166a-596a-4dc0-c487-a2037b7e13b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images: 18\n",
            "Train Labels: 18\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Images:\", len(os.listdir(\"/content/leftImg8bit/train/\")))\n",
        "print(\"Train Labels:\", len(os.listdir(\"/content/gtFine/train/\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qafiZBb5yC0b",
        "outputId": "ca708147-f894-45aa-c1ca-1264da6b9375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test images :  6\n"
          ]
        }
      ],
      "source": [
        "print(\"test images : \", len(os.listdir('/content/leftImg8bit/test')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q1cFO0jJcA8"
      },
      "source": [
        "**Global Valrible**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NSFJ69oJiMF"
      },
      "outputs": [],
      "source": [
        "img_height = 384\n",
        "img_width = 768\n",
        "batch_size = 1\n",
        "final_batch_size = batch_size * strategy.num_replicas_in_sync\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Y6CZKmCbNd"
      },
      "source": [
        "**loading images and labels from directry for training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzTJuxSUyT19"
      },
      "outputs": [],
      "source": [
        "def load_img():\n",
        "    train_dir = '/content/leftImg8bit/train'\n",
        "    train_image_cities = os.listdir(train_dir)\n",
        "    train_images = []\n",
        "    for city in sorted(train_image_cities):\n",
        "        train_city = os.path.join(train_dir, city)\n",
        "        images = sorted([os.path.join(train_city, img) for img in os.listdir(train_city) if img.endswith('.png')])\n",
        "        train_images.extend(images)\n",
        "    return train_images\n",
        "\n",
        "def load_labels():\n",
        "    train_dir = '/content/gtFine/train'\n",
        "    train_labels_cities = os.listdir(train_dir)\n",
        "    train_labels = []\n",
        "    for city in sorted(train_labels_cities):\n",
        "        train_city_label = os.path.join(train_dir, city)\n",
        "        labels = sorted([os.path.join(train_city_label, f) for f in os.listdir(train_city_label) if f.endswith('_gtFine_labelIds.png')])\n",
        "        train_labels.extend(labels)\n",
        "    return train_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGkR1OkdChy9"
      },
      "source": [
        "**reading images from path**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR2-lYACFmLh"
      },
      "outputs": [],
      "source": [
        "def read_img(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, (img_height, img_width))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def read_labels(label_path):\n",
        "    label = tf.io.read_file(label_path)\n",
        "    label = tf.io.decode_png(label, channels=1)\n",
        "    label = tf.image.resize(label, (img_height, img_width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return tf.cast(label, tf.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMQ2HsmKQtqF"
      },
      "source": [
        "**augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArL30hPWQzQc"
      },
      "outputs": [],
      "source": [
        "def process_data(image_path, label_path):\n",
        "    image = read_img(image_path)\n",
        "    label = read_labels(label_path)\n",
        "    return image, label\n",
        "\n",
        "# def augment(image, label):\n",
        "#     label = tf.cast(label, tf.float32)\n",
        "#     if tf.random.uniform(()) > 0.5:\n",
        "#         image = tf.image.flip_left_right(image)\n",
        "#         label = tf.image.flip_left_right(label)\n",
        "#     image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "#     label = tf.cast(label, tf.uint8)\n",
        "#     return image, label\n",
        "\n",
        "def augment(image, label):\n",
        "    # Convert to float32 for image manipulations\n",
        "    image = tf.cast(image, tf.float32)\n",
        "\n",
        "    # Flip left-right\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        label = tf.image.flip_left_right(label)\n",
        "\n",
        "    # Random brightness\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "\n",
        "    # Random contrast\n",
        "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)\n",
        "\n",
        "    # Random saturation\n",
        "    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)\n",
        "\n",
        "    # Random hue\n",
        "    image = tf.image.random_hue(image, max_delta=0.05)\n",
        "\n",
        "    # Random cropping to the target resolution (e.g., 512x1024 or 768x1536)\n",
        "    image, label = tf.image.resize_with_crop_or_pad(image, target_height=384, target_width=768), tf.image.resize_with_crop_or_pad(label, target_height=384, target_width=768)\n",
        "\n",
        "    # Label should stay in uint8 after augmentation\n",
        "    label = tf.cast(label, tf.uint8)\n",
        "\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMrQX_bwIrwt"
      },
      "source": [
        "**creating dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiZ4wr51HQR_",
        "outputId": "2c647ffb-6a2a-4033-9fa9-decdb457d44d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Train Images: 2975\n",
            "Total Train Labels: 2975\n"
          ]
        }
      ],
      "source": [
        "def map_labels_tf(label):\n",
        "    label = tf.squeeze(label, axis=-1)\n",
        "\n",
        "    original_ids = tf.constant([7, 8, 11, 12, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33], dtype=tf.int32)\n",
        "    train_ids = tf.range(19, dtype=tf.int32)\n",
        "    lookup = tf.fill([34], 255)\n",
        "    lookup = tf.tensor_scatter_nd_update(lookup, tf.expand_dims(original_ids, axis=1), train_ids)\n",
        "    y_mapped = tf.gather(lookup, tf.cast(label, tf.int32))\n",
        "    return tf.expand_dims(y_mapped, axis=-1)\n",
        "\n",
        "images = load_img()\n",
        "labels = load_labels()\n",
        "assert len(images) == len(labels), f\"Mismatch: {len(images)} images, {len(labels)} labels\"\n",
        "print(\"Total Train Images:\", len(images))\n",
        "print(\"Total Train Labels:\", len(labels))\n",
        "\n",
        "def replace_ignore_label(image, label):\n",
        "    label = tf.where(label == 255, 0, label)  # label is int32, so 255 and 0 are fine\n",
        "    return image, label\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "options = tf.data.Options()\n",
        "options.experimental_deterministic = False  # Allow non-deterministic order for better performance\n",
        "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA  # Shard data across TPU replicas\n",
        "\n",
        "# Apply options to the dataset\n",
        "train_dataset = train_dataset.with_options(options)\n",
        "\n",
        "train_dataset = train_dataset.map(process_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset =train_dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.map(lambda image, label: (image, map_labels_tf(label)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.map(replace_ignore_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=100).cache().batch(final_batch_size,drop_remainder=True)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "train_dataset = strategy.experimental_distribute_dataset(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtUwaeoBgZ1-"
      },
      "source": [
        "**loading images and labels from directry for validiation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt2sAOA9gZP4"
      },
      "outputs": [],
      "source": [
        "def load_img_val():\n",
        "    train_dir = '/content/leftImg8bit/val'\n",
        "    train_image_cities = os.listdir(train_dir)\n",
        "    train_images = []\n",
        "\n",
        "    for city in sorted(train_image_cities):\n",
        "        train_city = os.path.join(train_dir, city)\n",
        "        images = sorted([os.path.join(train_city, img) for img in os.listdir(train_city) if img.endswith('.png')])\n",
        "        train_images.extend(images)\n",
        "\n",
        "    return train_images\n",
        "\n",
        "def load_labels_val():\n",
        "    train_dir = '/content/gtFine/val'\n",
        "    train_labels_cities = os.listdir(train_dir)\n",
        "    train_labels = []\n",
        "    for city in sorted(train_labels_cities):\n",
        "        train_city_label = os.path.join(train_dir, city)\n",
        "        labels = sorted([os.path.join(train_city_label, f) for f in os.listdir(train_city_label) if f.endswith('_gtFine_labelIds.png')])\n",
        "        train_labels.extend(labels)\n",
        "    return train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akUFQg0SgqWq"
      },
      "outputs": [],
      "source": [
        "def read_img_val(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, (img_height, img_width))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def read_labels_val(label_path):\n",
        "    label = tf.io.read_file(label_path)\n",
        "    label = tf.io.decode_png(label, channels=1)\n",
        "    label = tf.image.resize(label, (img_height, img_width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return tf.cast(label, tf.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLLrc6JQgv15",
        "outputId": "c515c0c7-c973-493c-ed5d-e383cf5878de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Train Images: 500\n",
            "Total Train Labels: 500\n"
          ]
        }
      ],
      "source": [
        "def process_data_val(image_path, label_path):\n",
        "    image = read_img(image_path)\n",
        "    label = read_labels(label_path)\n",
        "    return image, label\n",
        "\n",
        "def map_labels_tf(label):\n",
        "    label = tf.squeeze(label, axis=-1)\n",
        "\n",
        "    original_ids = tf.constant([7, 8, 11, 12, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33], dtype=tf.int32)\n",
        "    train_ids = tf.range(19, dtype=tf.int32)\n",
        "    lookup = tf.fill([34], 255)\n",
        "    lookup = tf.tensor_scatter_nd_update(lookup, tf.expand_dims(original_ids, axis=1), train_ids)\n",
        "    y_mapped = tf.gather(lookup, tf.cast(label, tf.int32))\n",
        "    return tf.expand_dims(y_mapped, axis=-1)\n",
        "\n",
        "images = load_img_val()\n",
        "labels = load_labels_val()\n",
        "assert len(images) == len(labels), f\"Mismatch: {len(images)} images, {len(labels)} labels\"\n",
        "print(\"Total Train Images:\", len(images))\n",
        "print(\"Total Train Labels:\", len(labels))\n",
        "\n",
        "def replace_ignore_label(image, label):\n",
        "    label = tf.where(label == 255, 0, label)  # label is int32, so 255 and 0 are fine\n",
        "    return image, label\n",
        "\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "options = tf.data.Options()\n",
        "options.experimental_deterministic = False  # Allow non-deterministic order for better performance\n",
        "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA  # Shard data across TPU replicas\n",
        "\n",
        "# Apply options to the dataset\n",
        "val_dataset = val_dataset.with_options(options)\n",
        "\n",
        "val_dataset = val_dataset.map(process_data_val, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "val_dataset = val_dataset.map(lambda image, label: (image, map_labels_tf(label)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.map(replace_ignore_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.shuffle(buffer_size=100).cache().batch(16,drop_remainder=True)\n",
        "val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset = strategy.experimental_distribute_dataset(val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWuEcsIvhHAl"
      },
      "source": [
        "**loading images and labels from directry for testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnpkmjsehZUW"
      },
      "outputs": [],
      "source": [
        "def load_img_test():\n",
        "    train_dir = '/content/leftImg8bit/test'\n",
        "    train_image_cities = os.listdir(train_dir)\n",
        "    train_images = []\n",
        "\n",
        "    for city in sorted(train_image_cities):\n",
        "        train_city = os.path.join(train_dir, city)\n",
        "        images = sorted([os.path.join(train_city, img) for img in os.listdir(train_city) if img.endswith('.png')])\n",
        "        train_images.extend(images)\n",
        "\n",
        "    return train_images\n",
        "\n",
        "def load_labels_test():\n",
        "    train_dir = '/content/gtFine/test'\n",
        "    train_labels_cities = os.listdir(train_dir)\n",
        "    train_labels = []\n",
        "    for city in sorted(train_labels_cities):\n",
        "        train_city_label = os.path.join(train_dir, city)\n",
        "        labels = sorted([os.path.join(train_city_label, f) for f in os.listdir(train_city_label) if f.endswith('_gtFine_labelIds.png')])\n",
        "        train_labels.extend(labels)\n",
        "    return train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w9CLcnqhqH9"
      },
      "outputs": [],
      "source": [
        "def read_img_test(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, (img_height, img_width))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def read_labels_test(label_path):\n",
        "    label = tf.io.read_file(label_path)\n",
        "    label = tf.io.decode_png(label, channels=1)\n",
        "    label = tf.image.resize(label, (img_height, img_width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return tf.cast(label, tf.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TQo6yfIh2J0"
      },
      "outputs": [],
      "source": [
        "def process_data_val(image_path, label_path):\n",
        "    image = read_img(image_path)\n",
        "    label = read_labels(label_path)\n",
        "    return image, label\n",
        "\n",
        "def map_labels_tf(label):\n",
        "    label = tf.squeeze(label, axis=-1)\n",
        "    original_ids = tf.constant([7, 8, 11, 12, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33], dtype=tf.int32)\n",
        "    train_ids = tf.range(19, dtype=tf.int32)\n",
        "    lookup = tf.fill([34], 255)\n",
        "    lookup = tf.tensor_scatter_nd_update(lookup, tf.expand_dims(original_ids, axis=1), train_ids)\n",
        "    y_mapped = tf.gather(lookup, tf.cast(label, tf.int32))\n",
        "    return tf.expand_dims(y_mapped, axis=-1)\n",
        "\n",
        "\n",
        "images = load_img_val()\n",
        "labels = load_labels_val()\n",
        "\n",
        "# Create TF Dataset\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "test_dataset = test_dataset.map(process_data_val, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.map(lambda image, label: (image, map_labels_tf(label)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.shuffle(buffer_size=1000).cache().batch(final_batch_size)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_dataset = strategy.experimental_distribute_dataset(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71fnRZr6XnEY"
      },
      "source": [
        "**FCN model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYYeYAZ7WKGM"
      },
      "outputs": [],
      "source": [
        "class Block(tf.keras.models.Model):\n",
        "    def __init__(self, n_conv, filters, kernel_size, activation, pool_size, pool_stride, block_name):\n",
        "        super().__init__()\n",
        "        self.conv_layers = [\n",
        "            tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding='same',\n",
        "                                   activation=activation, name=f\"{block_name}_conv{i+1}\")\n",
        "            for i in range(n_conv)\n",
        "        ]\n",
        "        self.pool = tf.keras.layers.MaxPool2D(pool_size=pool_size, strides=pool_stride, name=f\"{block_name}_pool\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for conv in self.conv_layers:\n",
        "            x = conv(x)\n",
        "        x = self.pool(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTQFaELPY5CU"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class Encoder(tf.keras.models.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(768,1536,3))\n",
        "\n",
        "\n",
        "        self.layer_names = [\n",
        "            'conv1_relu',\n",
        "            'conv2_block3_out',\n",
        "            'conv3_block4_out',\n",
        "            'conv4_block6_out',\n",
        "            'conv5_block3_out'\n",
        "        ]\n",
        "\n",
        "        self.outputs = [base_model.get_layer(name).output for name in self.layer_names]\n",
        "        self.encoder = tf.keras.Model(inputs=base_model.input, outputs=self.outputs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.encoder(inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7urJTNYZAVO"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.models.Model):\n",
        "    def __init__(self, nclasses=19):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.upsample1 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu1 = tf.keras.layers.ReLU()\n",
        "\n",
        "        self.upsample2 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu2 = tf.keras.layers.ReLU()\n",
        "\n",
        "        self.upsample3 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False)\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu3 = tf.keras.layers.ReLU()\n",
        "\n",
        "\n",
        "        self.skip1 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), padding='same', use_bias=False)\n",
        "        self.skip1_bn = tf.keras.layers.BatchNormalization()\n",
        "        self.skip1_relu = tf.keras.layers.ReLU()\n",
        "\n",
        "        self.skip2 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), padding='same', use_bias=False)\n",
        "        self.skip2_bn = tf.keras.layers.BatchNormalization()\n",
        "        self.skip2_relu = tf.keras.layers.ReLU()\n",
        "\n",
        "        self.skip3 = tf.keras.layers.Conv2D(nclasses, kernel_size=(1, 1), padding='same', use_bias=False)\n",
        "        self.skip3_bn = tf.keras.layers.BatchNormalization()\n",
        "        self.skip3_relu = tf.keras.layers.ReLU()\n",
        "\n",
        "\n",
        "        self.add1 = tf.keras.layers.Add()\n",
        "        self.add2 = tf.keras.layers.Add()\n",
        "        self.add3 = tf.keras.layers.Add()\n",
        "\n",
        "\n",
        "        self.fcn4 = tf.keras.layers.Conv2DTranspose(nclasses, kernel_size=(4, 4), strides=(4, 4), padding='same', name='fcn4')\n",
        "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        p1, p2, p3, p4, p5 = inputs\n",
        "\n",
        "\n",
        "        o = self.upsample1(p5)\n",
        "        o = self.bn1(o, training=training)\n",
        "        o = self.relu1(o)\n",
        "        skip = self.skip1(p4)\n",
        "        skip = self.skip1_bn(skip, training=training)\n",
        "        skip = self.skip1_relu(skip)\n",
        "        o = self.add1([o, skip])\n",
        "\n",
        "\n",
        "        o = self.upsample2(o)\n",
        "        o = self.bn2(o, training=training)\n",
        "        o = self.relu2(o)\n",
        "        skip = self.skip2(p3)\n",
        "        skip = self.skip2_bn(skip, training=training)\n",
        "        skip = self.skip2_relu(skip)\n",
        "        o = self.add2([o, skip])\n",
        "\n",
        "\n",
        "        o = self.upsample3(o)\n",
        "        o = self.bn3(o, training=training)\n",
        "        o = self.relu3(o)\n",
        "        skip = self.skip3(p2)\n",
        "        skip = self.skip3_bn(skip, training=training)\n",
        "        skip = self.skip3_relu(skip)\n",
        "        o = self.add3([o, skip])\n",
        "\n",
        "\n",
        "        fcn4 = self.fcn4(o)\n",
        "\n",
        "        return self.softmax(fcn4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WXzcbDYZOJ5"
      },
      "outputs": [],
      "source": [
        "class FCN(tf.keras.models.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.Encoder = Encoder()\n",
        "        self.Decoder = Decoder()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.Encoder(inputs)\n",
        "        x = self.Decoder(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxRi_CXd411R",
        "outputId": "59ca04e3-3fbf-4e6f-d7d5-10c5b44c2f3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Model built: True\n",
            "Trainable variables: ['kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'gamma', 'beta', 'kernel', 'gamma', 'beta', 'kernel', 'gamma', 'beta', 'kernel', 'gamma', 'beta', 'kernel', 'gamma', 'beta', 'kernel', 'gamma', 'beta', 'kernel', 'bias']\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    fcn = FCN()\n",
        "    sample_input = tf.random.uniform((1, 768, 1536, 3))\n",
        "    fcn(sample_input)\n",
        "    print(\"Model built:\", fcn.built)\n",
        "    print(\"Trainable variables:\", [var.name for var in fcn.trainable_variables])\n",
        "\n",
        "\n",
        "# fcn = FCN()\n",
        "# sample_input = tf.random.uniform((1, 512, 512, 3))\n",
        "# fcn(sample_input)\n",
        "# print(\"Model built:\", fcn.built)\n",
        "# print(\"Trainable variables:\", [var.name for var in fcn.trainable_variables])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18i2b45Cb4Wy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t99faxaF2nJN"
      },
      "source": [
        "**UNET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1GY9fuSZy2v"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters,block_name , kernel_size=3 , strides = (1,1) , activation='relu'):\n",
        "    super().__init__()\n",
        "    self.conv = [tf.keras.layers.Conv2D(filters=n_filters , strides=strides , kernel_size=(kernel_size, kernel_size) , activation='relu', name=f\"{block_name}_conv{i+1}\", padding='same') for i in range (2)]\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    for layer in self.conv:\n",
        "      x = layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnXkjW1yBK2t"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters , pool_size , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.convBlock = ConvBlock(n_filters=n_filters , block_name=block_name, strides=(1,1))\n",
        "    self.pool = tf.keras.layers.MaxPooling2D(pool_size=pool_size)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate = dropout)\n",
        "  def call (self, inputs) :\n",
        "    f = self.convBlock(inputs)\n",
        "    p = self.pool(f)\n",
        "    p = self.dropout(p)\n",
        "    return f , p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGj_gAVYCtKV"
      },
      "outputs": [],
      "source": [
        "class Encoder (tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder1 = EncoderBlock(64 , pool_size=(2,2),dropout=0.3 , block_name = 'block1')\n",
        "    self.encoder2 = EncoderBlock(128 , pool_size=(2,2),dropout=0.3 , block_name = 'block2')\n",
        "    self.encoder3 = EncoderBlock(256 , pool_size=(2,2),dropout=0.3 , block_name = 'block3')\n",
        "    self.encoder4 = EncoderBlock(512, pool_size=(2,2),dropout=0.3 , block_name = 'block4')\n",
        "  def call(self, inputs):\n",
        "    f1,p1=self.encoder1(inputs)\n",
        "    f2,p2 = self.encoder2(p1)\n",
        "    f3 , p3 = self.encoder3(p2)\n",
        "    f4,p4 = self.encoder4(p3)\n",
        "    return p4,(f1,f2,f3,f4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnixQBJQEYxk"
      },
      "outputs": [],
      "source": [
        "class BottleNeck(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.convBlock=ConvBlock(1024, block_name = 'bottleneck' )\n",
        "  def call(self, inputs):\n",
        "    x = self.convBlock(inputs)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRG3BTRoKBp_"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters ,dropout,block_name , kernel_size= (3,3),strides = (2,2)  ):\n",
        "    super().__init__()\n",
        "    self.convTranspose = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size = kernel_size , strides=strides , padding = 'same')\n",
        "    self.concat = tf.keras.layers.Concatenate()\n",
        "    self.DropOut = tf.keras.layers.Dropout(dropout)\n",
        "    self.convBlock = ConvBlock(n_filters=n_filters , block_name =block_name  )\n",
        "  def call(self, inputs , convOutput):\n",
        "    u=self.convTranspose(inputs)\n",
        "    c = self.concat([u,convOutput])\n",
        "    c= self.DropOut(c)\n",
        "    c = self.convBlock(c)\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38eh4paxNH6X"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Decoder (tf.keras.models.Model):\n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "    self.Decoder1 = DecoderBlock(n_filters=512 , dropout=0.3 , block_name='Decoder1')\n",
        "    self.Decoder2 = DecoderBlock(n_filters=256 , dropout=0.3 , block_name='Decoder2')\n",
        "    self.Decoder3 = DecoderBlock(n_filters=128 , dropout=0.3 , block_name='Decoder3')\n",
        "    self.Decoder4 = DecoderBlock(n_filters=64 , dropout=0.3 , block_name='Decoder4')\n",
        "    self.final_conv = tf.keras.layers.Conv2D(19, kernel_size=(1,1))\n",
        "  def call(self , inputs , conv):\n",
        "    f1, f2 , f3, f4 = conv\n",
        "    c6 = self.Decoder1(inputs, f4 )\n",
        "    c7 = self.Decoder2(c6,f3)\n",
        "    c8 = self.Decoder3(c7,f2)\n",
        "    c9= self.Decoder4(c8, f1)\n",
        "    outputs = self.final_conv(c9)\n",
        "    return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50M1jLpNPbHe"
      },
      "outputs": [],
      "source": [
        "class Unet (tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Encoder = Encoder()\n",
        "    self.BottleNeck = BottleNeck()\n",
        "    self.Decoder = Decoder()\n",
        "  def call(self , inputs):\n",
        "    encoder_output,convs = self.Encoder(inputs)\n",
        "    bottleNeck_output = self.BottleNeck(encoder_output)\n",
        "    output = self.Decoder(bottleNeck_output,convs)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHQD28WFRJyl"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZQzYRpVi9dS"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  unet = Unet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcAZx14LYsBv"
      },
      "source": [
        "***UNET ++***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky0wpWCXYxRo"
      },
      "outputs": [],
      "source": [
        "class Unet_plus_plus_convolutional_block(tf.keras.models.Model):\n",
        "  def __init__(self, n_filters , block_name , activation = 'relu',kernel_size=(3,3)  ):\n",
        "    super().__init__()\n",
        "    self.conv_layers = [tf.keras.layers.Conv2D(filters=n_filters , kernel_size= kernel_size , name=f\"{block_name}_conv{i+1}\",padding = 'same', activation='relu') for i in range (2)]\n",
        "  def call(self, inputs) :\n",
        "    x = inputs\n",
        "    for layer in self.conv_layers:\n",
        "      x=layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoVSW0wMbWTe"
      },
      "outputs": [],
      "source": [
        "class Encoder_Block_for_unt_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self,  n_filters , pool_size , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.conv = Unet_plus_plus_convolutional_block(n_filters=n_filters, block_name=block_name)\n",
        "    self.pool = tf.keras.layers.MaxPooling2D(pool_size=pool_size)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate =dropout)\n",
        "  def call(self,inputs):\n",
        "    f=self.conv(inputs)\n",
        "    p = self.pool(f)\n",
        "    p = self.dropout(p)\n",
        "    return f ,  p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cis-R7e4ozB"
      },
      "outputs": [],
      "source": [
        "class Encoder_for_unt_plus_plus(tf.keras.models.Model):\n",
        "    def __init__(self, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        base = tf.keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=(384, 768, 3))\n",
        "\n",
        "        self.layer_names = [\n",
        "            'conv1_relu',\n",
        "            'conv2_block3_out',\n",
        "            'conv3_block4_out',\n",
        "            'conv4_block6_out'\n",
        "        ]\n",
        "        self.backbone = tf.keras.models.Model(inputs=base.input,\n",
        "                              outputs=[base.get_layer(n).output for n in self.layer_names])\n",
        "\n",
        "        self.pools = [tf.keras.layers.MaxPooling2D((2,2), name=f\"pool{i+1}\")\n",
        "                      for i in range(4)]\n",
        "        self.drops = [tf.keras.layers.Dropout(dropout_rate, name=f\"drop{i+1}\")\n",
        "                      for i in range(4)]\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        feats = self.backbone(x)\n",
        "        pools = []\n",
        "\n",
        "        for i, f in enumerate(feats):\n",
        "            p = self.pools[i](f)\n",
        "            p = self.drops[i](p)\n",
        "            pools.append(p)\n",
        "        return feats, pools\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-p5Nw8n7TcD"
      },
      "outputs": [],
      "source": [
        "class BottleNeck_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self ):\n",
        "    super().__init__()\n",
        "    self.bottle_neck = Unet_plus_plus_convolutional_block(n_filters=1024 , block_name = 'bottle_neck'  )\n",
        "  def call(self, inputs):\n",
        "    x = self.bottle_neck(inputs)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKqiRcGr83D5"
      },
      "outputs": [],
      "source": [
        "class Decoder_Block_for_unet_plus_plus(tf.keras.models.Model):\n",
        "  def __init__(self,n_filters  , dropout,block_name):\n",
        "    super().__init__()\n",
        "    self.conv = Unet_plus_plus_convolutional_block(n_filters=n_filters , block_name = block_name)\n",
        "    self.dropout = tf.keras.layers.Dropout(rate = dropout)\n",
        "    self.convTranspose = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size = (3,3) , strides=(2,2) , padding = 'same')\n",
        "    self.concat = tf.keras.layers.Concatenate()\n",
        "\n",
        "  def call(self, conv_output_conc, inputs):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      if inputs.shape[1] <= 1 or inputs.shape[2] <= 1:\n",
        "\n",
        "          target_size = (max(conv_output_conc.shape[1], 1), max(conv_output_conc.shape[2], 1))\n",
        "          u = tf.image.resize(inputs, target_size)\n",
        "      else:\n",
        "          u = self.convTranspose(inputs)\n",
        "\n",
        "\n",
        "      if u.shape[1:3] != conv_output_conc.shape[1:3]:\n",
        "\n",
        "          if u.shape[1] * u.shape[2] < conv_output_conc.shape[1] * conv_output_conc.shape[2]:\n",
        "              u = tf.image.resize(u, (conv_output_conc.shape[1], conv_output_conc.shape[2]))\n",
        "          else:\n",
        "              conv_output_conc = tf.image.resize(conv_output_conc, (u.shape[1], u.shape[2]))\n",
        "\n",
        "      c = self.concat([u, conv_output_conc])\n",
        "      c = self.dropout(c)\n",
        "      c = self.conv(c)\n",
        "      return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9jopfkfASqD"
      },
      "outputs": [],
      "source": [
        "class Decoder_for_unet_plus_plus(tf.keras.models.Model):\n",
        "    def __init__(self, num_classes=19):\n",
        "        super().__init__()\n",
        "\n",
        "        # Decoders with corresponding filters\n",
        "        self.decoder11 = Decoder_Block_for_unet_plus_plus(n_filters=64, dropout=0.3, block_name='skip_conv_block_11')\n",
        "        self.decoder12 = Decoder_Block_for_unet_plus_plus(n_filters=64, dropout=0.3, block_name='skip_conv_block_12')\n",
        "        self.decoder13 = Decoder_Block_for_unet_plus_plus(n_filters=64, dropout=0.3, block_name='skip_conv_block_13')\n",
        "        self.decoder14 = Decoder_Block_for_unet_plus_plus(n_filters=64, dropout=0.3, block_name='skip_conv_block_14')\n",
        "        self.decoder15 = Decoder_Block_for_unet_plus_plus(n_filters=256, dropout=0.3, block_name='skip_conv_block_15')  # Newly added\n",
        "\n",
        "        self.decoder21 = Decoder_Block_for_unet_plus_plus(n_filters=128, dropout=0.3, block_name='skip_conv_block_21')\n",
        "        self.decoder22 = Decoder_Block_for_unet_plus_plus(n_filters=128, dropout=0.3, block_name='skip_conv_block_22')\n",
        "        self.decoder23 = Decoder_Block_for_unet_plus_plus(n_filters=128, dropout=0.3, block_name='skip_conv_block_23')\n",
        "\n",
        "        self.decoder31 = Decoder_Block_for_unet_plus_plus(n_filters=256, dropout=0.3, block_name='skip_conv_block_31')\n",
        "        self.decoder32 = Decoder_Block_for_unet_plus_plus(n_filters=256, dropout=0.3, block_name='skip_conv_block_32')\n",
        "\n",
        "        self.decoder41 = Decoder_Block_for_unet_plus_plus(n_filters=512, dropout=0.3, block_name='skip_conv_block_41')\n",
        "\n",
        "        self.bottle_neck = BottleNeck_for_unet_plus_plus()\n",
        "\n",
        "        # Concatenation layers\n",
        "        self.concat12 = tf.keras.layers.Concatenate()\n",
        "        self.concat13 = tf.keras.layers.Concatenate()\n",
        "        self.concat14 = tf.keras.layers.Concatenate()\n",
        "\n",
        "        self.concat22 = tf.keras.layers.Concatenate()\n",
        "        self.concat23 = tf.keras.layers.Concatenate()\n",
        "        self.concat32 = tf.keras.layers.Concatenate()\n",
        "\n",
        "        # Output conv layers for deep supervision\n",
        "        self.output_layer11 = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='sigmoid' if num_classes == 1 else 'softmax', padding='same', name='output_layer11')\n",
        "        self.output_layer12 = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='sigmoid' if num_classes == 1 else 'softmax', padding='same', name='output_layer12')\n",
        "        self.output_layer13 = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='sigmoid' if num_classes == 1 else 'softmax', padding='same', name='output_layer13')\n",
        "        self.output_layer14 = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='sigmoid' if num_classes == 1 else 'softmax', padding='same', name='output_layer14')\n",
        "        self.output_layer15 = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='sigmoid' if num_classes == 1 else 'softmax', padding='same', name='output_layer15')  # Final output layer\n",
        "\n",
        "    def call(self, convs_cont, pool_cont):\n",
        "        f1, f2, f3, f4 = convs_cont\n",
        "        p1, p2, p3, p4 = pool_cont\n",
        "\n",
        "        # Check for invalid shapes\n",
        "        for i, feat in enumerate([f1, f2, f3, f4, p1, p2, p3, p4]):\n",
        "            if feat.shape[1] < 1 or feat.shape[2] < 1:\n",
        "                print(f\"Warning: Feature map {i} has invalid dimensions: {feat.shape}\")\n",
        "\n",
        "        # Bottleneck\n",
        "        p5 = self.bottle_neck(p4)\n",
        "\n",
        "        # Decoder stage\n",
        "        decoder41 = self.decoder41(f4, p5)\n",
        "\n",
        "        decoder31 = self.decoder31(f3, p4)\n",
        "        conc32 = self.concat32([f3, decoder31])\n",
        "        decoder32 = self.decoder32(conc32, decoder41)\n",
        "\n",
        "        decoder21 = self.decoder21(f2, p3)\n",
        "        conc22 = self.concat22([f2, decoder21])\n",
        "        decoder22 = self.decoder22(conc22, decoder31)\n",
        "        conc23 = self.concat23([f2, decoder21, decoder22])\n",
        "        decoder23 = self.decoder23(conc23, decoder32)\n",
        "\n",
        "        decoder11 = self.decoder11(f1, p2)\n",
        "        conc12 = self.concat12([f1, decoder11])\n",
        "        decoder12 = self.decoder12(conc12, decoder21)\n",
        "        conc13 = self.concat13([f1, decoder11, decoder12])\n",
        "        decoder13 = self.decoder13(conc13, decoder22)\n",
        "        conc14 = self.concat14([f1, decoder11, decoder12, decoder13])\n",
        "        decoder14 = self.decoder14(conc14, decoder23)\n",
        "\n",
        "        # NEW: decoder15 added to increase final feature dimension to 256\n",
        "        decoder15 = self.decoder15(decoder14, decoder14)  # same tensor as both inputs; could be updated later\n",
        "\n",
        "        # Outputs\n",
        "        output11 = self.output_layer11(decoder11)\n",
        "        output12 = self.output_layer12(decoder12)\n",
        "        output13 = self.output_layer13(decoder13)\n",
        "        output14 = self.output_layer14(decoder14)\n",
        "        output15 = self.output_layer15(decoder15)\n",
        "\n",
        "        return output11, output12, output13, output14, output15\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QbqnnYvIS-v"
      },
      "outputs": [],
      "source": [
        "class Unet_plus_plus(tf.keras.models.Model):\n",
        "    def __init__(self, min_input_size=16):\n",
        "        super().__init__()\n",
        "        self.min_input_size = min_input_size\n",
        "        self.encoder = Encoder_for_unt_plus_plus()\n",
        "        self.decoder = Decoder_for_unet_plus_plus()\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        input_shape = inputs.shape\n",
        "        if input_shape[1] < self.min_input_size or input_shape[2] < self.min_input_size:\n",
        "            raise ValueError(f\"Input image dimensions must be at least {self.min_input_size}x{self.min_input_size}\")\n",
        "\n",
        "        y, z = self.encoder(inputs)\n",
        "        output11, output12, output13, output14,output15 = self.decoder(y, z)\n",
        "        return output11, output12, output13, output14,output15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhvmJp5cJ86_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93522fa6-574d-4927-c75a-01a06a97ca17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model built: True\n",
            "Trainable variables: ['kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias']\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  unet_plus_plus = Unet_plus_plus()\n",
        "  sample_input = tf.random.uniform((1, 384, 768, 3))\n",
        "  unet_plus_plus(sample_input)  # Builds the model\n",
        "  print(\"Model built:\", unet_plus_plus.built)\n",
        "  print(\"Trainable variables:\", [var.name for var in unet_plus_plus.trainable_variables])\n",
        "\n",
        "# unet_plus_plus = Unet_plus_plus()\n",
        "# sample_input = tf.random.uniform((1, 512, 512, 3))\n",
        "# unet_plus_plus(sample_input)  # Builds the model\n",
        "# print(\"Model built:\", unet_plus_plus.built)\n",
        "# print(\"Trainable variables:\", [var.name for var in unet_plus_plus.trainable_variables])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unet_plus_plus.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "rZLih_tQGH_A",
        "outputId": "b6ce4f67-03dd-40e6-94bc-330f886ad197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"unet_plus_plus\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"unet_plus_plus\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder_for_unt_plus_plus       │ ?                      │     \u001b[38;5;34m8,589,184\u001b[0m │\n",
              "│ (\u001b[38;5;33mEncoder_for_unt_plus_plus\u001b[0m)     │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_for_unet_plus_plus      │ ?                      │    \u001b[38;5;34m47,793,375\u001b[0m │\n",
              "│ (\u001b[38;5;33mDecoder_for_unet_plus_plus\u001b[0m)    │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder_for_unt_plus_plus       │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,589,184</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder_for_unt_plus_plus</span>)     │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_for_unet_plus_plus      │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">47,793,375</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder_for_unet_plus_plus</span>)    │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m56,382,559\u001b[0m (215.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,382,559</span> (215.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,351,967\u001b[0m (214.97 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,351,967</span> (214.97 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m30,592\u001b[0m (119.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,592</span> (119.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYo7fCzYMLoO"
      },
      "source": [
        "**testing code for model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG9N7x9NpFX8"
      },
      "source": [
        "**defining loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zgqf26VNpmJO"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class DiceLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, smooth=1e-6, name=\"DiceLoss\"):\n",
        "        super().__init__(reduction=tf.keras.losses.Reduction.NONE, name=name)\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def compute_per_sample(self, y_true, y_pred):\n",
        "        dtype = y_pred.dtype\n",
        "\n",
        "        # one-hot encode\n",
        "        y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=19, dtype=dtype)\n",
        "\n",
        "        # valid mask\n",
        "        mask = tf.not_equal(y_true, 255)\n",
        "        mask = tf.cast(mask, dtype)[..., tf.newaxis]  # add channel dimension\n",
        "\n",
        "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
        "\n",
        "        # intersection and union\n",
        "        intersection = tf.reduce_sum(y_true_one_hot * y_pred * mask, axis=[1,2])\n",
        "        union = tf.reduce_sum(y_true_one_hot * mask, axis=[1,2]) + tf.reduce_sum(y_pred * mask, axis=[1,2])\n",
        "\n",
        "        dice_per_class = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
        "        dice_loss_per_sample = 1.0 - tf.reduce_mean(dice_per_class, axis=-1)  # (batch,)\n",
        "\n",
        "        return dice_loss_per_sample\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        # fallback for model.fit()\n",
        "        return tf.reduce_mean(self.compute_per_sample(y_true, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "class SemanticSegmentationLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, alpha=1.0, beta=1.0, name=\"SemanticSegmentationLoss\"):\n",
        "        super().__init__(reduction=tf.keras.losses.Reduction.NONE, name=name)\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.dice_loss = DiceLoss()\n",
        "        self.class_weights = tf.constant([\n",
        "            0.1, 0.2, 0.5, 0.7, 0.8,\n",
        "            1.0, 1.2, 1.3, 0.6, 0.9,\n",
        "            0.4, 1.5, 1.6, 1.1, 1.7,\n",
        "            1.8, 1.9, 2.0, 2.1\n",
        "        ], dtype=tf.float32)\n",
        "        self.ce_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "            from_logits=False, reduction='none'\n",
        "        )\n",
        "\n",
        "    def compute_per_sample(self, y_true, y_pred):\n",
        "        dtype = y_pred.dtype\n",
        "\n",
        "        # squeeze labels\n",
        "        y_true = tf.squeeze(y_true, axis=-1)\n",
        "\n",
        "        # mask invalid pixels (label 255)\n",
        "        mask_bool = tf.not_equal(y_true, 255)\n",
        "        mask = tf.cast(mask_bool, dtype)\n",
        "\n",
        "        # one-hot encode labels\n",
        "        y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=19, dtype=dtype)\n",
        "\n",
        "        # cross-entropy loss per pixel\n",
        "        ce = self.ce_loss_fn(y_true, y_pred)  # (batch, height, width)\n",
        "        ce = tf.cast(ce, dtype)\n",
        "\n",
        "        # weighted cross-entropy\n",
        "        class_weights = tf.cast(self.class_weights, dtype)\n",
        "        pixel_weights = tf.tensordot(y_true_one_hot, class_weights, axes=([-1], [0]))\n",
        "        ce_weighted = ce * pixel_weights * mask\n",
        "\n",
        "        # per-sample (batch) CE loss\n",
        "        sum_ce = tf.reduce_sum(ce_weighted, axis=[1,2])\n",
        "        count_px = tf.reduce_sum(mask, axis=[1,2])\n",
        "        ce_per_sample = sum_ce / tf.maximum(count_px, 1e-6)\n",
        "\n",
        "        # dice loss per sample\n",
        "        dice_per_sample = self.dice_loss.compute_per_sample(y_true, y_pred)\n",
        "\n",
        "        # combined weighted loss\n",
        "        total_loss_per_sample = self.alpha * ce_per_sample + self.beta * dice_per_sample\n",
        "        return total_loss_per_sample  # (batch,)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        # fallback for model.fit()\n",
        "        return tf.reduce_mean(self.compute_per_sample(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qUgykK3kVo7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLllqFTgQm4p"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class DeepSupervisionLoss:\n",
        "    def __init__(self, ignore_last=False):\n",
        "        self.ignore_last = ignore_last\n",
        "        # Model ends in Softmax → from_logits=False\n",
        "        self.ce_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "            from_logits=False,\n",
        "            reduction=tf.keras.losses.Reduction.NONE\n",
        "        )\n",
        "\n",
        "    def _resize_y_true(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Ensure y_true is a [B, H, W, 1] tensor at runtime, then\n",
        "        resize it via nearest-neighbor to match y_pred's spatial dims.\n",
        "        \"\"\"\n",
        "        # 1) get dynamic shape\n",
        "        shape = tf.shape(y_true)          # [batch, H, W]\n",
        "        b, h, w = shape[0], shape[1], shape[2]\n",
        "\n",
        "        # 2) reshape into concrete 4-D: [B, H, W, 1]\n",
        "        y_true_4d = tf.reshape(y_true, [b, h, w, 1])\n",
        "\n",
        "        # 3) target size from y_pred\n",
        "        target_h = tf.shape(y_pred)[1]\n",
        "        target_w = tf.shape(y_pred)[2]\n",
        "\n",
        "        # 4) resize\n",
        "        y_true_resized = tf.image.resize(\n",
        "            y_true_4d,\n",
        "            size=(target_h, target_w),\n",
        "            method='nearest'\n",
        "        )\n",
        "        # 5) squeeze back to [B, H', W']\n",
        "        y_true_resized = tf.squeeze(y_true_resized, axis=-1)\n",
        "        return tf.cast(y_true_resized, tf.int32)\n",
        "\n",
        "    def _ce_per_sample(self, y_true, y_pred):\n",
        "        # resize labels to match this prediction's shape\n",
        "        y_true_resized = self._resize_y_true(y_true, y_pred)  # (B, H', W')\n",
        "        # compute per-pixel CE → (B, H', W')\n",
        "        ce_map = self.ce_loss_fn(y_true_resized, y_pred)\n",
        "        # average spatially → (B,)\n",
        "        return tf.reduce_mean(ce_map, axis=[1,2])\n",
        "\n",
        "    def compute_per_sample(self, y_true, y_preds):\n",
        "        \"\"\"\n",
        "        y_preds: list of predictions at various scales [(B,H1,W1,C), (B,H2,W2,C), ...]\n",
        "        Returns a tensor of shape (B,) containing the average loss per sample.\n",
        "        \"\"\"\n",
        "        total = 0.0\n",
        "        preds = y_preds[:-1] if self.ignore_last else y_preds\n",
        "        count = tf.cast(len(preds), tf.float32)\n",
        "\n",
        "        for y_pred in preds:\n",
        "            total += self._ce_per_sample(y_true, y_pred)  # adds (B,)\n",
        "\n",
        "        return total / count  # (B,)\n",
        "\n",
        "    def compute_batch_loss(self, y_true, y_preds):\n",
        "        \"\"\"\n",
        "        Reduces the (B,) per-sample losses to a single scalar.\n",
        "        \"\"\"\n",
        "        per_sample = self.compute_per_sample(y_true, y_preds)\n",
        "        return tf.reduce_mean(per_sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGS2N0sJsZWd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqLy6d_fQqWr"
      },
      "source": [
        "**IOU metric**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyxUTVNmwvIY"
      },
      "outputs": [],
      "source": [
        "class IOUMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, name=\"iou\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = 1e-6\n",
        "        self.sum_intersection = self.add_weight(name=\"sum_intersection\", shape=(n_classes,), initializer=\"zeros\")\n",
        "        self.sum_union = self.add_weight(name=\"sum_union\", shape=(n_classes,), initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "\n",
        "\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "\n",
        "        # Fix here ➡️  mask 255\n",
        "        valid_mask = tf.not_equal(y_true, 255)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        y_true = tf.boolean_mask(y_true, valid_mask)\n",
        "        y_pred = tf.boolean_mask(y_pred, valid_mask)\n",
        "\n",
        "        cm = tf.math.confusion_matrix(\n",
        "            tf.reshape(y_true, [-1]),\n",
        "            tf.reshape(y_pred, [-1]),\n",
        "            num_classes=self.n_classes,\n",
        "            dtype=tf.float32\n",
        "        )\n",
        "\n",
        "        intersection = tf.linalg.diag_part(cm)\n",
        "        union = tf.reduce_sum(cm, axis=0) + tf.reduce_sum(cm, axis=1) - tf.linalg.diag_part(cm)\n",
        "\n",
        "        self.sum_intersection.assign_add(intersection)\n",
        "        self.sum_union.assign_add(union)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def result(self):\n",
        "        iou = (self.sum_intersection + self.smooth) / (self.sum_union + self.smooth)\n",
        "        mean_iou = tf.reduce_mean(iou)\n",
        "        return mean_iou\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.sum_intersection.assign(tf.zeros_like(self.sum_intersection))\n",
        "        self.sum_union.assign(tf.zeros_like(self.sum_union))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb5ZLJrUQxgx"
      },
      "source": [
        "**per class IOU metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVQfJePV-tjG"
      },
      "outputs": [],
      "source": [
        "class PerClassIOUMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, name=\"iou_per_class\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = 1e-6\n",
        "        self.sum_intersection = self.add_weight(name=\"sum_intersection\", shape=(n_classes,), initializer=\"zeros\")\n",
        "        self.sum_union = self.add_weight(name=\"sum_union\", shape=(n_classes,), initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # y_true = tf.squeeze(y_true, axis=-1)\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "\n",
        "        y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=self.n_classes)\n",
        "        y_pred_one_hot = tf.one_hot(tf.cast(y_pred, tf.int32), depth=self.n_classes)\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true_one_hot * y_pred_one_hot, axis=[0, 1,2])\n",
        "        union = tf.reduce_sum(y_true_one_hot, axis=[0, 1,2]) + tf.reduce_sum(y_pred_one_hot, axis=[0, 1,2]) - intersection\n",
        "\n",
        "        self.sum_intersection.assign_add(intersection)\n",
        "        self.sum_union.assign_add(union)\n",
        "\n",
        "\n",
        "    def result(self):\n",
        "        return (self.sum_intersection + self.smooth) / (self.sum_union + self.smooth)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.sum_intersection.assign(tf.zeros_like(self.sum_intersection))\n",
        "        self.sum_union.assign(tf.zeros_like(self.sum_union))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI8rv85Uic1C"
      },
      "source": [
        "**Dice Coeficient Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVd2Y6GxVtPl"
      },
      "outputs": [],
      "source": [
        "class Dice_Coefficent_matrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, name='dice_coefficient', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = 1e-6\n",
        "        self.total_dice = self.add_weight(name=\"total_dice\", initializer=\"zeros\")\n",
        "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # y_true = tf.squeeze(y_true, axis=-1)\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "\n",
        "        y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=self.n_classes)\n",
        "        y_pred_one_hot = tf.one_hot(tf.cast(y_pred, tf.int32), depth=self.n_classes)\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true_one_hot * y_pred_one_hot, axis=[1, 2])\n",
        "        total = tf.reduce_sum(y_true_one_hot, axis=[1, 2]) + tf.reduce_sum(y_pred_one_hot, axis=[1, 2])\n",
        "\n",
        "        dice = (2.0 * intersection + self.smooth) / (total + self.smooth)\n",
        "        mean_dice = tf.reduce_mean(dice)\n",
        "\n",
        "        self.total_dice.assign_add(mean_dice)\n",
        "        self.count.assign_add(1.0)\n",
        "\n",
        "    def result(self):\n",
        "        return self.total_dice / tf.maximum(self.count, 1.0)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.total_dice.assign(0.0)\n",
        "        self.count.assign(0.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLNA7ijum2vZ"
      },
      "source": [
        "**per class_dice_coefficent metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd-b0q9nmYZd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class PerClassDiceCoefficientMatrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes=19, name=\"dice_per_class\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.smooth = 1e-6\n",
        "        self.sum_intersection = self.add_weight(name=\"sum_intersection\", shape=(n_classes,), initializer=\"zeros\")\n",
        "        self.sum_union = self.add_weight(name=\"sum_union\", shape=(n_classes,), initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # y_true = tf.squeeze(y_true, axis=-1)  # This line is commented, but it might be useful if needed\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "\n",
        "        y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=self.n_classes)\n",
        "        y_pred_one_hot = tf.one_hot(tf.cast(y_pred, tf.int32), depth=self.n_classes)\n",
        "\n",
        "        intersection = tf.reduce_sum(y_true_one_hot * y_pred_one_hot, axis=[0, 1, 2])\n",
        "        total = tf.reduce_sum(y_true_one_hot, axis=[0, 1, 2]) + tf.reduce_sum(y_pred_one_hot, axis=[0, 1, 2])\n",
        "\n",
        "        self.sum_intersection.assign_add(intersection)\n",
        "        self.sum_union.assign_add(total)\n",
        "\n",
        "    def result(self):\n",
        "        return (2.0 * self.sum_intersection + self.smooth) / (self.sum_union + self.smooth)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.sum_intersection.assign(tf.zeros_like(self.sum_intersection))\n",
        "        self.sum_union.assign(tf.zeros_like(self.sum_union))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkxRcmDDnKth"
      },
      "source": [
        "**Pixel Accurcy Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boqIP7CWm8Gy"
      },
      "outputs": [],
      "source": [
        "class Pixel_accurcy_metrics(tf.keras.metrics.Metric):\n",
        "    def __init__(self, n_classes = 19,name=\"pixel_accuracy\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.correct = self.add_weight(name=\"correct\", initializer=\"zeros\")\n",
        "        self.total = self.add_weight(name=\"total\", initializer=\"zeros\")\n",
        "        self.n_classes = n_classes\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # y_true = tf.squeeze(y_true, axis=-1)\n",
        "        y_pred = tf.cast(tf.argmax(y_pred, axis=-1),tf.int32)\n",
        "\n",
        "        correct = tf.reduce_sum(tf.cast(tf.equal(y_true, y_pred), tf.float32))\n",
        "        total = tf.size(y_true)\n",
        "\n",
        "        self.correct.assign_add(correct)\n",
        "        self.total.assign_add(total)\n",
        "\n",
        "    def result(self):\n",
        "        return self.correct / tf.maximum(self.total, 1.0)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.correct.assign(0)\n",
        "        self.total.assign(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGylMVcRYdeJ",
        "outputId": "8fe8a923-ae5c-4862-9e1c-9006f1e05ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean IoU: 0.027055593207478523\n",
            "Per-class IoU: [0.02548602 0.02543284 0.02570365 0.02538647 0.02571644 0.02557905\n",
            " 0.02588027 0.02565226 0.02570602 0.02579551 0.02544035 0.02540225\n",
            " 0.02555792 0.02554174 0.02560015 0.0255853  0.02549845 0.02561004\n",
            " 0.02574098]\n",
            "Mean Dice: 0.049913082271814346\n",
            "Per-class Dice: [0.04970525 0.04960411 0.05011905 0.04951591 0.05014337 0.04988216\n",
            " 0.05045476 0.05002136 0.05012355 0.05029367 0.04961839 0.04954592\n",
            " 0.04984199 0.04981122 0.04992227 0.04989405 0.04972889 0.04994109\n",
            " 0.05019002]\n",
            "Pixel Accuracy: 0.04741859436035156\n"
          ]
        }
      ],
      "source": [
        "batch_size = 16\n",
        "height = 768\n",
        "width = 1536\n",
        "num_classes = 19\n",
        "\n",
        "y_true = tf.random.uniform((batch_size, height, width), minval=0, maxval=num_classes, dtype=tf.int32)\n",
        "y_true = tf.where(tf.random.uniform((batch_size, height, width)) > 0.9, 255, y_true)\n",
        "\n",
        "y_pred = tf.random.uniform((batch_size, height, width, num_classes), minval=0, maxval=1, dtype=tf.float32)\n",
        "y_pred = y_pred / tf.reduce_sum(y_pred, axis=-1, keepdims=True)  # Softmax-like normalization\n",
        "\n",
        "# Initialize metrics\n",
        "mean_iou = IOUMetric(n_classes=num_classes)\n",
        "per_class_iou = PerClassIOUMetric(n_classes=num_classes)\n",
        "mean_dice = Dice_Coefficent_matrics(n_classes=num_classes)\n",
        "per_class_dice = PerClassDiceCoefficientMatrics(n_classes=num_classes)\n",
        "pixel_acc = Pixel_accurcy_metrics(n_classes=num_classes)\n",
        "\n",
        "# Update states\n",
        "mean_iou.update_state(y_true, y_pred)\n",
        "per_class_iou.update_state(y_true, y_pred)\n",
        "mean_dice.update_state(y_true, y_pred)\n",
        "per_class_dice.update_state(y_true, y_pred)  # Note: Bug here, should be y_true, y_pred\n",
        "pixel_acc.update_state(y_true, y_pred)\n",
        "\n",
        "# Get results\n",
        "print(f\"Mean IoU: {mean_iou.result().numpy()}\")\n",
        "print(f\"Per-class IoU: {per_class_iou.result().numpy()}\")\n",
        "print(f\"Mean Dice: {mean_dice.result().numpy()}\")\n",
        "print(f\"Per-class Dice: {per_class_dice.result().numpy()}\")\n",
        "print(f\"Pixel Accuracy: {pixel_acc.result().numpy()}\")\n",
        "\n",
        "# Reset states (just to show it works)\n",
        "mean_iou.reset_state()\n",
        "per_class_iou.reset_state()\n",
        "mean_dice.reset_state()\n",
        "per_class_dice.reset_state()\n",
        "pixel_acc.reset_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbxDqaLiU2LZ"
      },
      "source": [
        "**optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkI53Row67bK"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    optimizer_fcn =tf.optimizers.AdamW(learning_rate=1e-5, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "    optimizer_unet = tf.optimizers.AdamW(learning_rate=5e-5, weight_decay=1e-5)\n",
        "    optimizer_unet_plus_plus =  tf.optimizers.AdamW(learning_rate=5e-4, weight_decay=1e-5)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j72q95Pjob9m"
      },
      "source": [
        "**checkPoint dirs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jolqu8_FoelE"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir_fcn = '/content/drive/MyDrive/CityScapes_model_checkpoints/fcn'\n",
        "checkpoint_dir_unet = '/content/drive/MyDrive/CityScapes_model_checkpoints/unet'\n",
        "checkpoint_dir_unet_plus_plus = '/content/drive/MyDrive/CityScapes_model_checkpoints/unet_plus_plus_new'\n",
        "fcn_log_dir = '/content/drive/MyDrive/CityScapes_model_checkpoints/fcn_log_dir'\n",
        "unet_log_dir = '/content/drive/MyDrive/CityScapes_model_checkpoints/unet_log_dir'\n",
        "unet_plus_plus_log_dir = '/content/drive/MyDrive/CityScapes_model_checkpoints/unet_plus_plus_new_log_dir'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr83oImgE-T7"
      },
      "source": [
        "**custom callbacks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az4V0gCqFDCt"
      },
      "outputs": [],
      "source": [
        "class Custom_checkpoint_Callback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, checkpoint_dir, model, optimizer, input_shape=(None,384,768,3)):\n",
        "        super().__init__()\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self._model = model\n",
        "        self._optimizer = optimizer\n",
        "\n",
        "\n",
        "\n",
        "        self._model.build(input_shape)\n",
        "\n",
        "\n",
        "        self.checkpoint = tf.train.Checkpoint(\n",
        "            model=self._model,\n",
        "            optimizer=self._optimizer,\n",
        "            epoch=tf.Variable(1, dtype=tf.int64)\n",
        "        )\n",
        "        self.ckpt_manager = tf.train.CheckpointManager(\n",
        "            self.checkpoint,\n",
        "            directory=self.checkpoint_dir,\n",
        "            max_to_keep=5\n",
        "        )\n",
        "        os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    def _initialize_optimizer_slots(self):\n",
        "        \"\"\"\n",
        "        Under the active tf.distribute.Strategy.scope(), call optimizer.build()\n",
        "        to create *all* slot variables (momentum, variance, etc.) for each\n",
        "        trainable variable.  No data needed.\n",
        "        \"\"\"\n",
        "        strategy = tf.distribute.get_strategy()\n",
        "        with strategy.scope():\n",
        "\n",
        "            self._optimizer.build(self._model.trainable_variables)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        self.checkpoint.epoch.assign(epoch)\n",
        "        path = self.ckpt_manager.save()\n",
        "        print(f\"\\n✅ Checkpoint saved for epoch {epoch} at {path}\")\n",
        "\n",
        "    def load_latest_model(self):\n",
        "        latest = self.ckpt_manager.latest_checkpoint\n",
        "        if latest:\n",
        "            print(\"🔧 Initializing optimizer slot variables (no data needed)…\")\n",
        "            self._initialize_optimizer_slots()\n",
        "            print(\"📦 Restoring checkpoint (model + optimizer state)…\")\n",
        "\n",
        "            self.checkpoint.restore(latest).assert_existing_objects_matched()\n",
        "            start = int(self.checkpoint.epoch.numpy())\n",
        "            print(f\"✅ Restored from {latest}, resuming at epoch {start}\")\n",
        "            return start\n",
        "        else:\n",
        "            print(\"🚀 No checkpoint found. Starting from epoch 1.\")\n",
        "            return 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_m7da_J8G566"
      },
      "outputs": [],
      "source": [
        "# class Custom_early_stopping_callback(tf.keras.callbacks.Callback):\n",
        "#   def __init__(self, paticance = 15  , min_delta = 1e-4):\n",
        "#     self.patiance = paticance\n",
        "#     self.min_delta = min_delta\n",
        "#     self.best_loss = {\n",
        "#         'fcn' : float('inf') ,\n",
        "#         'unet' : float('inf') ,\n",
        "#         'unet_plus_plus' : float('inf')\n",
        "#     }\n",
        "#     self.stoped_epoch = 0\n",
        "#     self.wait = {\n",
        "#         'fcn' : 0 ,\n",
        "#         'unet': 0 ,\n",
        "#         'unet_plus_plus' : 0\n",
        "#     }\n",
        "#   def early_stoping(self, epoch , val_loss):\n",
        "#     if (val_loss['fcn']< self.best_loss['fcn']-self.min_delta):\n",
        "#       self.best_loss['fcn'] = val_loss['fcn']\n",
        "#       self.wait['fcn'] = 0\n",
        "#     else :\n",
        "#       self.wait['fcn'] +=1\n",
        "#     if (val_loss['unet']< self.best_loss['unet']-self.min_delta):\n",
        "#       self.best_loss['unet'] = val_loss['unet']\n",
        "#       self.wait['unet'] = 0\n",
        "#     else  :\n",
        "#       self.wait['unet']+=1\n",
        "#     if (val_loss['unet_plus_plus']< self.best_loss['unet_plus_plus']-self.min_delta):\n",
        "#       self.best_loss['unet_plus_plus'] = val_loss['unet_plus_plus']\n",
        "#       self.wait['unet_plus_plus'] = 0\n",
        "#     else :\n",
        "#       self.wait['unet_plus_plus']+=1\n",
        "#     if self.wait['fcn'] > self.patiance and self.wait['unet']>self.patiance and self.wait['unet_plus_plus']>self.patiance:\n",
        "#       self.stoped_epoch  =epoch\n",
        "#       print (f'early stoping trainig at {self.stoped_epoch}')\n",
        "#       return True\n",
        "#     return False\n",
        "\n",
        "\n",
        "class Custom_early_stopping_callback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, paticance = 15 , min_delta=1e-4):\n",
        "    super().__init__()\n",
        "    self.paticance=paticance\n",
        "    self.min_delta = min_delta\n",
        "    self.best_loss = float('inf')\n",
        "    self.stoped_epoch = 0\n",
        "    self.wait = 0\n",
        "\n",
        "\n",
        "  def early_stoping(self, epoch , val_loss):\n",
        "    if val_loss < self.best_loss-self.min_delta :\n",
        "      self.best_loss = val_loss\n",
        "      self.wait = 0\n",
        "\n",
        "    else :\n",
        "      self.wait +=1\n",
        "    if self.wait > self.paticance  :\n",
        "      self.stoped_epoch  =epoch\n",
        "      print (f'early stoping trainig at {self.stoped_epoch}')\n",
        "      return True\n",
        "    return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGFZO7E5UMgH"
      },
      "outputs": [],
      "source": [
        "# class Custom_learning_rate_schedule(tf.keras.callbacks.Callback):\n",
        "#   def __init__(self , optimizer_fcn , optimizer_unet , optimizer_unet_plus_plus , factor = 0.5 , patiance = 5 , min_delta = 1e-4 , min_lr = 1e-8 ):\n",
        "#     super().__init__()\n",
        "#     self.factor = factor\n",
        "#     self.patiance = patiance\n",
        "#     self.min_delta = min_delta\n",
        "#     self.min_lr = min_lr\n",
        "#     self.best_val_loss = {\n",
        "#         'fcn' : float('inf') ,\n",
        "#         'unet': float('inf') ,\n",
        "#         'unet_plus_plus' : float('inf')\n",
        "#     }\n",
        "#     self.optimzer  = {\n",
        "#         'fcn' : optimizer_fcn ,\n",
        "#         'unet' : optimizer_fcn ,\n",
        "#         'unet_plus_plus': optimizer_unet_plus_plus\n",
        "#     }\n",
        "#     self.wait = {\n",
        "#         'fcn' : 0 ,\n",
        "#         'unet': 0 ,\n",
        "#         'unet_plus_plus' : 0\n",
        "#     }\n",
        "#   def change_learning_rate(self, epoch , val_loss):\n",
        "#     for model_name , val_loss in val_loss.items():\n",
        "#       if val_loss < self.best_val_loss[model_name]-self.min_delta:\n",
        "#         self.best_val_loss[model_name] = val_loss\n",
        "#         self.wait[model_name] = 0\n",
        "#       else :\n",
        "#         self.wait[model_name] +=1\n",
        "#       if self.wait[model_name] >= self.patiance :\n",
        "#         old_lr = self.optimzer[model_name].lr.numpy()\n",
        "#         new_lr = tf.maximum(old_lr*self.factor , self.min_lr)\n",
        "#         self.optimzer[model_name].lr.assign(new_lr)\n",
        "#         print (f'learning rate for model : {model_name} has been change from : {old_lr} to the new lr : {new_lr} at epoch : {epoch}')\n",
        "#         self.wait= 0\n",
        "\n",
        "class Custom_learning_rate_schedule(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, optimizer , factor = 0.5 , min_delta = 1e-4 ,paticance = 3 , min_lr = 1e-8):\n",
        "    super().__init__()\n",
        "    self.optimizer = optimizer\n",
        "    self.factor = factor\n",
        "    self.patiance = paticance\n",
        "    self.min_lr= min_lr\n",
        "    self.min_delta = min_delta\n",
        "    self.best_loss = float('inf')\n",
        "    self.wait = 0\n",
        "\n",
        "  def change_learning_rate(self, epoch , val_loss) :\n",
        "    if val_loss < self.best_loss-self.min_delta :\n",
        "      self.best_loss = val_loss\n",
        "      self.wait = 0\n",
        "    else :\n",
        "      self.wait +=1\n",
        "    if self.wait > self.patiance :\n",
        "      old_lr = self.optimizer.learning_rate.numpy()\n",
        "      new_lr = tf.maximum(old_lr*self.factor , self.min_lr)\n",
        "      self.optimizer.learning_rate.assign(new_lr)\n",
        "      print (f'learning rate for model  has been change from : {old_lr} to the new lr : {new_lr} at epoch : {epoch}')\n",
        "      self.wait = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOdDahlsAFkl"
      },
      "outputs": [],
      "source": [
        "# class Custom_Training_logger_callback(tf.keras.callbacks.Callback):\n",
        "#   def __init__(self, batches_per_epoch):\n",
        "#     super().__init__()\n",
        "#     self.model_name = ['fcn' , 'unet' , 'unet_plus_plus']\n",
        "#     self.batch_per_epoch = batches_per_epoch\n",
        "#     self.batch_table_display = None\n",
        "#     self.graph_display = None\n",
        "#   def On_epoch_begin(self, epoch ):\n",
        "#     print(f'Epoch begins : {epoch}')\n",
        "#     self.progress_bar = tqdm(total=self.batch_per_epoch,desc=f'epoch {epoch}')\n",
        "#     self.batch_table_data = []\n",
        "#     self.batch_loss = {\n",
        "#         'fcn':[] ,\n",
        "#         'unet': [] ,\n",
        "#         'unet_plus_plus' :[]\n",
        "#     }\n",
        "\n",
        "#     self.epoch_table_data = []\n",
        "#     display(HTML('<h3>📊 Batch-wise Loss Table</h3>'))\n",
        "\n",
        "\n",
        "#   def on_batch_end(self, batch , epoch,data = None):\n",
        "#     self.progress_bar.set_postfix({\n",
        "#         f'epoch :{epoch} , batch ': batch / self.batch_per_epoch\n",
        "#         })\n",
        "#     self.progress_bar.update(1)\n",
        "#     if data == None :\n",
        "#       return\n",
        "#     self.batch_table_data.append({\n",
        "#         'batch': batch ,\n",
        "#         'fcn_loss' : data['fcn']['loss'] ,\n",
        "\n",
        "#         'unet_loss' :data['unet']['loss'],\n",
        "\n",
        "#         'unet_plus_plus_loss' : data['unet_plus_plus']['loss']  ,\n",
        "\n",
        "#         'fcn_IOUMetric' : data['fcn']['metrics']['IOUMetric'] ,\n",
        "#         'fcn_PerClassIOUMetric' : data['fcn']['metrics']['PerClassIOUMetric'],\n",
        "#         'fcn_Dice_Coefficent_matrics' :  data['fcn']['metrics']['Dice_Coefficent_matrics'],\n",
        "#         'fcn_PerClassDiceCoefficientMatrics' : data['fcn']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "#         'fcn_Pixel_accurcy_metrics' : data['fcn']['metrics']['Pixel_accurcy_metrics'],\n",
        "#         'unet_IOUMetric' : data['unet']['metrics']['IOUMetric'] ,\n",
        "#         'unet_PerClassIOUMetric' : data['unet']['metrics']['PerClassIOUMetric'],\n",
        "#         'unet_Dice_Coefficent_matrics' :  data['unet']['metrics']['Dice_Coefficent_matrics'],\n",
        "#         'unet_PerClassDiceCoefficientMatrics' : data['unet']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "#         'unet_Pixel_accurcy_metrics' : data['unet']['metrics']['Pixel_accurcy_metrics'],\n",
        "#         'unet_plus_plus_IOUMetric' : data['unet_plus_plus']['metrics']['IOUMetric'] ,\n",
        "#         'unet_plus_plus_PerClassIOUMetric' : data['unet_plus_plus']['metrics']['PerClassIOUMetric'],\n",
        "#         'unet_plus_plus_Dice_Coefficent_matrics' :  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics'],\n",
        "#         'unet_plus_plus_PerClassDiceCoefficientMatrics' : data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "#         'unet_plus_plus_Pixel_accurcy_metrics' : data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics'],\n",
        "\n",
        "#       })\n",
        "\n",
        "\n",
        "#     df = pd.DataFrame(self.batch_table_data)\n",
        "\n",
        "#     if self.batch_table_display is None:\n",
        "#       self.batch_table_display = display( df, display_id=True)\n",
        "#     else :\n",
        "#       self.batch_table_display.update(df)\n",
        "#     self.batch_loss['fcn'].append(data['fcn']['loss'])\n",
        "#     self.batch_loss['unet'].append(data['unet']['loss'])\n",
        "#     self.batch_loss['unet_plus_plus'].append(data['unet_plus_plus']['loss'])\n",
        "\n",
        "#     fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "#     axes[0].plot(self.batch_loss['fcn'], label='FCN Loss', marker='o')\n",
        "#     axes[0].plot(self.batch_loss['unet'], label='U-Net Loss', marker='o')\n",
        "#     axes[0].plot(self.batch_loss['unet_plus_plus'], label='U-Net++ Loss', marker='o')\n",
        "#     axes[0].set_title('Training Loss')\n",
        "#     axes[0].set_xlabel('Batch')\n",
        "#     axes[0].set_ylabel('Loss')\n",
        "#     axes[0].legend()\n",
        "#     axes[0].grid(True)\n",
        "\n",
        "\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     if self.graph_display is None:\n",
        "#       display(HTML('<h3>📉 Loss Graphs (Batch-wise Trend)</h3>'))\n",
        "#       self.graph_display = display(fig, display_id=True)\n",
        "#     else:\n",
        "#       self.graph_display.update(fig)\n",
        "#     plt.close(fig)\n",
        "\n",
        "\n",
        "#   def on_epoch_end(self , epoch ,data):\n",
        "#     self.progress_bar.close()\n",
        "#     if data == None :\n",
        "#       return\n",
        "#     display(HTML('<h3>📊 Epoch Summary Table</h3>'))\n",
        "#     self.epoch_table_data.append({\n",
        "#         'epoch': epoch ,\n",
        "#         'fcn_loss' : data['fcn']['loss'] ,\n",
        "#         'fcn_val_loss':data['fcn']['val_loss'] ,\n",
        "#         'unet_loss' :data['unet']['loss'],\n",
        "#         'unet_val_loss' : data['unet']['val_loss'] ,\n",
        "#         'unet_plus_plus_loss' : data['unet_plus_plus']['loss']  ,\n",
        "#         'unet_plus_plus_val_loss' : data['unet_plus_plus']['val_loss'],\n",
        "#         'fcn_IOUMetric' : data['fcn']['metrics']['IOUMetric'] ,\n",
        "#         'fcn_PerClassIOUMetric' : data['fcn']['metrics']['PerClassIOUMetric'],\n",
        "#         'fcn_Dice_Coefficent_matrics' :  data['fcn']['metrics']['Dice_Coefficent_matrics'],\n",
        "#         'fcn_PerClassDiceCoefficientMatrics' : data['fcn']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "#         'fcn_Pixel_accurcy_metrics' : data['fcn']['metrics']['Pixel_accurcy_metrics'],\n",
        "#         'unet_IOUMetric' : data['unet']['metrics']['IOUMetric'] ,\n",
        "#         'unet_PerClassIOUMetric' : data['unet']['metrics']['PerClassIOUMetric'],\n",
        "#         'unet_Dice_Coefficent_matrics' :  data['unet']['metrics']['Dice_Coefficent_matrics'],\n",
        "#         'unet_PerClassDiceCoefficientMatrics' : data['unet']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "#         'unet_Pixel_accurcy_metrics' : data['unet']['metrics']['Pixel_accurcy_metrics'],\n",
        "#         'unet_plus_plus_IOUMetric' : data['unet_plus_plus']['metrics']['IOUMetric'] ,\n",
        "#         'unet_plus_plus_PerClassIOUMetric' : data['unet_plus_plus']['metrics']['PerClassIOUMetric'],\n",
        "#         'unet_plus_plus_Dice_Coefficent_matrics' :  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics'],\n",
        "#         'unet_plus_plus_PerClassDiceCoefficientMatrics' : data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "#         'unet_plus_plus_Pixel_accurcy_metrics' : data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics'],\n",
        "\n",
        "#         'fcn_IOUMetric_val' : data['fcn']['metrics']['IOUMetric_val'] ,\n",
        "#         'fcn_PerClassIOUMetric_val' : data['fcn']['metrics']['PerClassIOUMetric_val'],\n",
        "#         'fcn_Dice_Coefficent_matrics_val' :  data['fcn']['metrics']['Dice_Coefficent_matrics_val'],\n",
        "#         'fcn_PerClassDiceCoefficientMatrics_val' : data['fcn']['metrics']['PerClassDiceCoefficientMatrics_val'],\n",
        "#         'fcn_Pixel_accurcy_metrics_val' : data['fcn']['metrics']['Pixel_accurcy_metrics_val'],\n",
        "#         'unet_IOUMetric_val' : data['unet']['metrics']['IOUMetric_val'] ,\n",
        "#         'unet_PerClassIOUMetric_val' : data['unet']['metrics']['PerClassIOUMetric_val'],\n",
        "#         'unet_Dice_Coefficent_matrics_val' :  data['unet']['metrics']['Dice_Coefficent_matrics_val'],\n",
        "#         'unet_PerClassDiceCoefficientMatrics_val' : data['unet']['metrics']['PerClassDiceCoefficientMatrics_val'],\n",
        "#         'unet_Pixel_accurcy_metrics_val' : data['unet']['metrics']['Pixel_accurcy_metrics_val'],\n",
        "#         'unet_plus_plus_IOUMetric_val' : data['unet_plus_plus']['metrics']['IOUMetric_val'] ,\n",
        "#         'unet_plus_plus_PerClassIOUMetric_val' : data['unet_plus_plus']['metrics']['PerClassIOUMetric_val'],\n",
        "#         'unet_plus_plus_Dice_Coefficent_matrics_val' :  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics_val'],\n",
        "#         'unet_plus_plus_PerClassDiceCoefficientMatrics_val' : data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics_val'],\n",
        "#         'unet_plus_plus_Pixel_accurcy_metrics_val' : data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics_val'],\n",
        "#       })\n",
        "#     df=pd.DataFrame(self.epoch_table_data)\n",
        "#     display(df)\n",
        "#     fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "#     axes[0].plot(self.batch_loss['fcn'], label='FCN Loss', marker='o')\n",
        "#     axes[0].plot(self.batch_loss['unet'], label='U-Net Loss', marker='o')\n",
        "#     axes[0].plot(self.batch_loss['unet_plus_plus'], label='U-Net++ Loss', marker='o')\n",
        "#     axes[0].set_title('Training Loss')\n",
        "#     axes[0].set_xlabel('Batch')\n",
        "#     axes[0].set_ylabel('Loss')\n",
        "#     axes[0].legend()\n",
        "#     axes[0].grid(True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     display(HTML(f'<h3>📉 Final Loss Graphs - Epoch {epoch + 1}</h3>'))\n",
        "#     self.final_graph_display = display(fig, display_id=f'final_graph_epoch_{epoch + 1}')\n",
        "#     plt.close(fig)\n",
        "\n",
        "\n",
        "\n",
        "class Custom_Training_logger_callback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self , batches_per_epoch) :\n",
        "    super().__init__()\n",
        "    self.batches_per_epoch = batches_per_epoch\n",
        "    self.batch_table_display = None\n",
        "    self.graph_display = None\n",
        "  def On_epoch_begin(self, epoch ):\n",
        "    print(f'Epoch begins : {epoch}')\n",
        "    self.progress_bar = tqdm(total=self.batches_per_epoch,desc=f'epoch {epoch}')\n",
        "    self.batch_table_data = []\n",
        "    self.batch_loss = []\n",
        "\n",
        "    self.epoch_table_data = []\n",
        "    display(HTML('<h3>📊 Batch-wise Loss Table</h3>'))\n",
        "\n",
        "\n",
        "  def on_batch_end(self, batch , epoch,data = None):\n",
        "    self.progress_bar.set_postfix({\n",
        "        f'epoch :{epoch} , batch ': batch / self.batches_per_epoch\n",
        "        })\n",
        "    self.progress_bar.update(1)\n",
        "    if data == None :\n",
        "      return\n",
        "    self.batch_table_data.append({\n",
        "        'batch': batch ,\n",
        "        'loss' : data['loss'],\n",
        "\n",
        "        'IOUMetric' : data['metrics']['IOUMetric'] ,\n",
        "        'PerClassIOUMetric' : data['metrics']['PerClassIOUMetric'],\n",
        "        'Dice_Coefficent_matrics' :  data['metrics']['Dice_Coefficent_matrics'],\n",
        "        'PerClassDiceCoefficientMatrics' : data['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'Pixel_accurcy_metrics' : data['metrics']['Pixel_accurcy_metrics'],\n",
        "      })\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(self.batch_table_data)\n",
        "\n",
        "    if self.batch_table_display is None:\n",
        "      self.batch_table_display = display( df, display_id=True)\n",
        "    else :\n",
        "      self.batch_table_display.update(df)\n",
        "    self.batch_loss.append(data['loss'])\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    axes[0].plot(self.batch_loss, label='Loss', marker='o')\n",
        "    axes[0].set_title('Training Loss')\n",
        "    axes[0].set_xlabel('Batch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if self.graph_display is None:\n",
        "      display(HTML('<h3>📉 Loss Graphs (Batch-wise Trend)</h3>'))\n",
        "      self.graph_display = display(fig, display_id=True)\n",
        "    else:\n",
        "      self.graph_display.update(fig)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "\n",
        "  def on_epoch_end(self , epoch ,data):\n",
        "    self.progress_bar.close()\n",
        "    if data == None :\n",
        "      return\n",
        "    display(HTML('<h3>📊 Epoch Summary Table</h3>'))\n",
        "    self.epoch_table_data.append({\n",
        "        'epoch': epoch ,\n",
        "        'loss' : data['loss'] ,\n",
        "        'val_loss':data['val_loss'] ,\n",
        "        'IOUMetric' : data['metrics']['IOUMetric'] ,\n",
        "        'PerClassIOUMetric' : data['metrics']['PerClassIOUMetric'],\n",
        "        'Dice_Coefficent_matrics' :  data['metrics']['Dice_Coefficent_matrics'],\n",
        "        'PerClassDiceCoefficientMatrics' : data['metrics']['PerClassDiceCoefficientMatrics'],\n",
        "        'Pixel_accurcy_metrics' : data['metrics']['Pixel_accurcy_metrics'],\n",
        "\n",
        "\n",
        "        'IOUMetric_val' : data['metrics']['IOUMetric_val'] ,\n",
        "        'PerClassIOUMetric_val' : data['metrics']['PerClassIOUMetric_val'],\n",
        "        'Dice_Coefficent_matrics_val' :  data['metrics']['Dice_Coefficent_matrics_val'],\n",
        "        'PerClassDiceCoefficientMatrics_val' : data['metrics']['PerClassDiceCoefficientMatrics_val'],\n",
        "        'Pixel_accurcy_metrics_val' : data['metrics']['Pixel_accurcy_metrics_val'],\n",
        "\n",
        "\n",
        "      })\n",
        "    df=pd.DataFrame(self.epoch_table_data)\n",
        "    display(df)\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    axes[0].plot(self.batch_loss, label='FCN Loss', marker='o')\n",
        "    axes[0].set_title('Training Loss')\n",
        "    axes[0].set_xlabel('Batch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    display(HTML(f'<h3>📉 Final Loss Graphs - Epoch {epoch + 1}</h3>'))\n",
        "    self.final_graph_display = display(fig, display_id=f'final_graph_epoch_{epoch + 1}')\n",
        "    plt.close(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZb3PnfxLOWu"
      },
      "outputs": [],
      "source": [
        "# class Master_callback(tf.keras.callbacks.Callback):\n",
        "#   def __init__(self, log_dir , checkpoint_dir_fcn , checkpoint_dir_unet ,                 checkpoint_dir_unet_plus_plus , fcn , unet , unet_plus_plus , optimizer_fcn ,optimizer_unet ,   optimizer_unet_plus_plus , batches_per_epoch  ):\n",
        "#     self.writer=tf.summary.create_file_writer(logdir=log_dir)\n",
        "#     # initilizing custom checkpoint callback\n",
        "#     self.ccc = Custom_checkpoint_Callabck(checkpoint_dir_fcn=checkpoint_dir_fcn,checkpoint_dir_unet=checkpoint_dir_unet , checkpoint_dir_unet_plus_plus=checkpoint_dir_unet_plus_plus , fcn = fcn , unet = unet , unet_plus_plus=unet_plus_plus , optimizer_fcn=optimizer_fcn , optimizer_unet=optimizer_unet , optimizer_unet_plus_plus=optimizer_unet_plus_plus )\n",
        "#     # initilizing custom ealry stoping callback\n",
        "#     self.cesc = Custom_early_stopping_callback()\n",
        "#     # initilizing custom learning rate scheduler\n",
        "#     self.clrs = Custom_learning_rate_schedule(optimizer_fcn=optimizer_fcn , optimizer_unet=optimizer_unet , optimizer_unet_plus_plus=optimizer_unet_plus_plus)\n",
        "#     # initilizing custom training logger\n",
        "#     self.ctlc = Custom_Training_logger_callback(batches_per_epoch=batches_per_epoch)\n",
        "#     self.stop = False\n",
        "\n",
        "#   def on_train_begin(self):\n",
        "#     return self.ccc.load_latest_model()\n",
        "#   def on_epoch_begin(self, epoch ):\n",
        "#     self.ctlc.On_epoch_begin(epoch)\n",
        "#   def on_batch_end(self,batch , epoch , data):\n",
        "#     self.ctlc.on_batch_end(batch , epoch , data)\n",
        "#   def on_epoch_end(self, epoch , data):\n",
        "#     self.ctlc.on_epoch_end(epoch , data)\n",
        "#     # summary -->\n",
        "#     with self.writer.as_default():\n",
        "#       tf.summary.scalar('fcn_loss' , data['fcn']['loss'],step=epoch)\n",
        "#       tf.summary.scalar('fcn_val_loss' , data['fcn']['val_loss'],step=epoch)\n",
        "#       tf.summary.scalar('unet_loss' , data['unet']['loss'],step=epoch)\n",
        "#       tf.summary.scalar('uent_val_loss' , data['unet']['val_loss'],step=epoch)\n",
        "#       tf.summary.scalar('unet_plus_plus_loss' , data['unet_plus_plus']['loss'],step=epoch)\n",
        "#       tf.summary.scalar('uent_plus_plus_val_loss' , data['unet_plus_plus']['val_loss'],step=epoch)\n",
        "#       tf.summary.scalar('fcn_IOUMetric',data['fcn']['metrics']['IOUMetric'] , step = epoch)\n",
        "#       tf.summary.scalar('fcn_PerClassIOUMetric' , data['fcn']['metrics']['PerClassIOUMetric'] , step = epoch)\n",
        "#       tf.summary.scalar('fcn_Dice_Coefficent_matrics' ,  data['fcn']['metrics']['Dice_Coefficent_matrics'] , step = epoch)\n",
        "#       tf.summary.scalar('fcn_PerClassDiceCoefficientMatrics' , data['fcn']['metrics']['PerClassDiceCoefficientMatrics'] , step = epoch)\n",
        "#       tf.summary.scalar('fcn_Pixel_accurcy_metrics' , data['fcn']['metrics']['Pixel_accurcy_metrics'], step = epoch)\n",
        "\n",
        "#       tf.summary.scalar('unet_IOUMetric',data['unet']['metrics']['IOUMetric'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_PerClassIOUMetric' , data['unet']['metrics']['PerClassIOUMetric'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_Dice_Coefficent_matrics' ,  data['unet']['metrics']['Dice_Coefficent_matrics'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_PerClassDiceCoefficientMatrics' , data['unet']['metrics']['PerClassDiceCoefficientMatrics'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_Pixel_accurcy_metrics' , data['unet']['metrics']['Pixel_accurcy_metrics'], step = epoch)\n",
        "\n",
        "#       tf.summary.scalar('unet_plus_plus_IOUMetric',data['unet_plus_plus']['metrics']['IOUMetric'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_plus_plus_PerClassIOUMetric' , data['unet_plus_plus']['metrics']['PerClassIOUMetric'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_plus_plus_Dice_Coefficent_matrics' ,  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_plus_plus_PerClassDiceCoefficientMatrics' , data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_plus_plus_Pixel_accurcy_metrics' , data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics'], step = epoch)\n",
        "\n",
        "#       tf.summary.scalar('fcn_IOUMetric_val',data['fcn']['metrics']['IOUMetric_val'] , step = epoch)\n",
        "#       tf.summary.scalar('fcn_PerClassIOUMetric_val' , data['fcn']['metrics']['PerClassIOUMetric_val'] , step = epoch)\n",
        "#       tf.summary.scalar('fcn_Dice_Coefficent_matrics_val' ,  data['fcn']['metrics']['Dice_Coefficent_matrics_val'] , step = epoch)\n",
        "#       tf.summary.scalar('fcn_PerClassDiceCoefficientMatrics_val' , data['fcn']['metrics']['PerClassDiceCoefficientMatrics_val'] , step = epoch)\n",
        "#       tf.summary.scalar('fcn_Pixel_accurcy_metrics_val' , data['fcn']['metrics']['Pixel_accurcy_metrics_val'], step = epoch)\n",
        "\n",
        "#       tf.summary.scalar('unet_IOUMetric_val',data['unet']['metrics']['IOUMetric_val'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_PerClassIOUMetric_val' , data['unet']['metrics']['PerClassIOUMetric_val'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_Dice_Coefficent_matrics_val' ,  data['unet']['metrics']['Dice_Coefficent_matrics_val'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_PerClassDiceCoefficientMatrics_val' , data['unet']['metrics']['PerClassDiceCoefficientMatrics_val'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_Pixel_accurcy_metrics_val' , data['unet']['metrics']['Pixel_accurcy_metrics__val'], step = epoch)\n",
        "\n",
        "#       tf.summary.scalar('unet_plus_plus_IOUMetric_val',data['unet_plus_plus']['metrics']['IOUMetric_val'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_plus_plus_PerClassIOUMetric_val' , data['unet_plus_plus']['metrics']['PerClassIOUMetric_val'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_plus_plus_Dice_Coefficent_matrics_val' ,  data['unet_plus_plus']['metrics']['Dice_Coefficent_matrics_val'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_plus_plus_PerClassDiceCoefficientMatrics_val' , data['unet_plus_plus']['metrics']['PerClassDiceCoefficientMatrics_val'] , step = epoch)\n",
        "#       tf.summary.scalar('unet_plus_plus_Pixel_accurcy_metrics_val' , data['unet_plus_plus']['metrics']['Pixel_accurcy_metrics_val'], step = epoch)\n",
        "#     self.writer.flush()\n",
        "#     self.ccc.on_epoch_end(epoch)\n",
        "#     self.clrs.change_learning_rate(epoch ,{\n",
        "#         'fcn' : data['fcn']['val_loss'] ,\n",
        "#         'unet' :  data['unet']['val_loss'] ,\n",
        "#         'unet_plus_plus' :  data['unet_plus_plus']['val_loss']\n",
        "#     })\n",
        "#     return self.cesc.early_stoping(epoch , {\n",
        "#         'fcn' : data['fcn']['val_loss'] ,\n",
        "#         'unet' :  data['unet']['val_loss'] ,\n",
        "#         'unet_plus_plus' :  data['unet_plus_plus']['val_loss']\n",
        "#     })\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Master_callback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, log_dir , checkpoint_dir ,  model ,  optimizer , batches_per_epoch  ):\n",
        "    self.writer=tf.summary.create_file_writer(logdir=log_dir)\n",
        "    # initilizing custom checkpoint callback\n",
        "    self.ccc = Custom_checkpoint_Callabck(checkpoint_dir=checkpoint_dir, model = model ,  optimizer=optimizer )\n",
        "    # initilizing custom ealry stoping callback\n",
        "    self.cesc = Custom_early_stopping_callback()\n",
        "    # initilizing custom learning rate scheduler\n",
        "    self.clrs = Custom_learning_rate_schedule(optimizer=optimizer)\n",
        "    # initilizing custom training logger\n",
        "    self.ctlc = Custom_Training_logger_callback(batches_per_epoch=batches_per_epoch)\n",
        "    self.stop = False\n",
        "\n",
        "  def on_train_begin(self):\n",
        "    return self.ccc.load_latest_model()\n",
        "\n",
        "  def on_epoch_begin(self, epoch ):\n",
        "    self.ctlc.On_epoch_begin(epoch)\n",
        "\n",
        "  def on_batch_end(self,batch , epoch , data):\n",
        "    self.ctlc.on_batch_end(batch , epoch , data)\n",
        "\n",
        "  def on_epoch_end(self, epoch , data):\n",
        "    self.ctlc.on_epoch_end(epoch , data)\n",
        "    # summary -->\n",
        "    with self.writer.as_default():\n",
        "      tf.summary.scalar('loss' , data['loss'],step=epoch)\n",
        "      tf.summary.scalar('fcn_val_loss' , data['val_loss'],step=epoch)\n",
        "\n",
        "      tf.summary.scalar('IOUMetric',data['metrics']['IOUMetric'] , step = epoch)\n",
        "      for i, iou_score in enumerate(data['metrics']['PerClassIOUMetric']):\n",
        "        tf.summary.scalar(f'PerClassIOUMetric_{i}', iou_score, step=epoch)\n",
        "\n",
        "      tf.summary.scalar('Dice_Coefficent_matrics' ,  data['metrics']['Dice_Coefficent_matrics'] , step = epoch)\n",
        "\n",
        "      for i, iou_score in enumerate(data['metrics']['PerClassDiceCoefficientMatrics']):\n",
        "        tf.summary.scalar(f'PerClassDiceCoefficientMatrics{i}', iou_score, step=epoch)\n",
        "      tf.summary.scalar('Pixel_accurcy_metrics' , data['metrics']['Pixel_accurcy_metrics'], step = epoch)\n",
        "\n",
        "\n",
        "      tf.summary.scalar('IOUMetric_val',data['metrics']['IOUMetric_val'] , step = epoch)\n",
        "      for i, iou_score in enumerate(data['metrics']['PerClassIOUMetric_val']):\n",
        "        tf.summary.scalar(f'PerClassIOUMetric_val_{i}', iou_score, step=epoch)\n",
        "      tf.summary.scalar('Dice_Coefficent_matrics_val' ,  data['metrics']['Dice_Coefficent_matrics_val'] , step = epoch)\n",
        "\n",
        "      for i, iou_score in enumerate(data['metrics']['PerClassDiceCoefficientMatrics_val']):\n",
        "        tf.summary.scalar(f'PerClassDiceCoefficientMatrics_val{i}', iou_score, step=epoch)\n",
        "      tf.summary.scalar('Pixel_accurcy_metrics_val' , data['metrics']['Pixel_accurcy_metrics_val'], step = epoch)\n",
        "\n",
        "\n",
        "    self.writer.flush()\n",
        "    self.ccc.on_epoch_end(epoch)\n",
        "    self.clrs.change_learning_rate(epoch ,val_loss=data['val_loss'])\n",
        "    return self.cesc.early_stoping(epoch ,val_loss = data['val_loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugK4Tt5h7myZ"
      },
      "source": [
        "**initilizing instances**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZhkibVdihjv"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  fcn_SemanticSegmentationLoss=SemanticSegmentationLoss()\n",
        "  unet_SemanticSegmentationLoss=SemanticSegmentationLoss()\n",
        "  deepSupervisionLoss=DeepSupervisionLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrB19aAPvme4"
      },
      "outputs": [],
      "source": [
        "batches_per_epoch =372\n",
        "fcn_master_callback =Master_callback(log_dir=fcn_log_dir , checkpoint_dir=checkpoint_dir_fcn  , model=fcn  ,batches_per_epoch=batches_per_epoch ,optimizer=optimizer_fcn )\n",
        "\n",
        "\n",
        "unet_master_callback =Master_callback(log_dir=unet_log_dir , checkpoint_dir=checkpoint_dir_unet  , model=unet  ,batches_per_epoch=batches_per_epoch ,optimizer=optimizer_unet )\n",
        "\n",
        "unet_plus_plus_master_callback =Master_callback(log_dir=unet_plus_plus_log_dir , checkpoint_dir=checkpoint_dir_unet_plus_plus  , model=unet_plus_plus  ,batches_per_epoch=batches_per_epoch ,optimizer=optimizer_unet_plus_plus )\n",
        "\n",
        "# fcn matrics\n",
        "with strategy.scope() :\n",
        "  fcn_IOUMetric = IOUMetric()\n",
        "  fcn_PerClassIOUMetric = PerClassIOUMetric()\n",
        "  fcn_Dice_Coefficent_matrics = Dice_Coefficent_matrics()\n",
        "  fcn_PerClassDiceCoefficientMatrics = PerClassDiceCoefficientMatrics()\n",
        "  fcn_Pixel_accurcy_metrics  = Pixel_accurcy_metrics()\n",
        "\n",
        "  fcn_IOUMetric_val = IOUMetric()\n",
        "  fcn_PerClassIOUMetric_val = PerClassIOUMetric()\n",
        "  fcn_Dice_Coefficent_matrics_val = Dice_Coefficent_matrics()\n",
        "  fcn_PerClassDiceCoefficientMatrics_val = PerClassDiceCoefficientMatrics()\n",
        "  fcn_Pixel_accurcy_metrics_val  = Pixel_accurcy_metrics()\n",
        "\n",
        "  # unet matrics\n",
        "  unet_IOUMetric = IOUMetric()\n",
        "  unet_PerClassIOUMetric = PerClassIOUMetric()\n",
        "  unet_Dice_Coefficent_matrics = Dice_Coefficent_matrics()\n",
        "  unet_PerClassDiceCoefficientMatrics = PerClassDiceCoefficientMatrics()\n",
        "  unet_Pixel_accurcy_metrics  = Pixel_accurcy_metrics()\n",
        "\n",
        "  unet_IOUMetric_val = IOUMetric()\n",
        "  unet_PerClassIOUMetric_val = PerClassIOUMetric()\n",
        "  unet_Dice_Coefficent_matrics_val = Dice_Coefficent_matrics()\n",
        "  unet_PerClassDiceCoefficientMatrics_val = PerClassDiceCoefficientMatrics()\n",
        "  unet_Pixel_accurcy_metrics_val  = Pixel_accurcy_metrics()\n",
        "\n",
        "  # unet_plus_plus matrics\n",
        "  unet_plus_plus_IOUMetric = IOUMetric()\n",
        "  unet_plus_plus_PerClassIOUMetric = PerClassIOUMetric()\n",
        "  unet_plus_plus_Dice_Coefficent_matrics = Dice_Coefficent_matrics()\n",
        "  unet_plus_plus_PerClassDiceCoefficientMatrics = PerClassDiceCoefficientMatrics()\n",
        "  unet_plus_plus_Pixel_accurcy_metrics  = Pixel_accurcy_metrics()\n",
        "\n",
        "  unet_plus_plus_IOUMetric_val = IOUMetric()\n",
        "  unet_plus_plus_PerClassIOUMetric_val = PerClassIOUMetric()\n",
        "  unet_plus_plus_Dice_Coefficent_matrics_val = Dice_Coefficent_matrics()\n",
        "  unet_plus_plus_PerClassDiceCoefficientMatrics_val = PerClassDiceCoefficientMatrics()\n",
        "  unet_plus_plus_Pixel_accurcy_metrics_val  = Pixel_accurcy_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ll7UPDu5VXW",
        "outputId": "20a0c117-7b34-4f9e-92ce-5d895eef3f6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.SemanticSegmentationLoss at 0x7ba0a46c2f50>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "fcn_SemanticSegmentationLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBt10VB8kHRA"
      },
      "source": [
        "**custom training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDw20qT5HhDJ"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  @tf.function\n",
        "  def train_step(x_train_batch, y_train_batch):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      # tf.print(\"Input shapes - x:\", x_train_batch.shape, \"y:\", y_train_batch.shape)\n",
        "      fcn_logits = fcn(x_train_batch)\n",
        "      # tf.print(\"fcn_logits shape:\", fcn_logits.shape)\n",
        "      fcn_loss = fcn_SemanticSegmentationLoss(y_true=y_train_batch, y_pred=fcn_logits)\n",
        "      # tf.print(\"fcn_loss computed:\", fcn_loss)\n",
        "      unet_logits = unet(x_train_batch)\n",
        "      # tf.print(\"unet_logits shape:\", unet_logits.shape)\n",
        "      unet_loss = unet_SemanticSegmentationLoss(y_true=y_train_batch, y_pred=unet_logits)\n",
        "      # tf.print(\"unet_loss computed:\", unet_loss)\n",
        "      unet_plus_plus_outputs = unet_plus_plus(x_train_batch)\n",
        "      unet_plus_plus_loss = deepSupervisionLoss(y_true=y_train_batch, y_pred=unet_plus_plus_outputs)\n",
        "      unet_plus_plus_logits = unet_plus_plus_outputs[-1]\n",
        "      # tf.print(\"unet_plus_plus_logits shape:\", unet_plus_plus_logits.shape)\n",
        "\n",
        "    fcn_gradients = tape.gradient(fcn_loss, fcn.trainable_variables)\n",
        "    # tf.print(\"fcn_gradients computed, length:\", len(fcn_gradients))\n",
        "    unet_gradients = tape.gradient(unet_loss, unet.trainable_variables)\n",
        "    # tf.print(\"unet_gradients computed, length:\", len(unet_gradients))\n",
        "    unet_plus_plus_gradients = tape.gradient(unet_plus_plus_loss, unet_plus_plus.trainable_variables)\n",
        "    # tf.print(\"unet_plus_plus_gradients computed, length:\", len(unet_plus_plus_gradients))\n",
        "\n",
        "\n",
        "\n",
        "    optimizer_fcn.apply_gradients(zip(fcn_gradients,fcn.trainable_variables))\n",
        "    optimizer_unet.apply_gradients(zip(unet_gradients,unet.trainable_variables))\n",
        "    optimizer_unet_plus_plus.apply_gradients(zip(unet_plus_plus_gradients , unet_plus_plus.trainable_variables))\n",
        "\n",
        "    fcn_IOUMetric.update_state(y_true=y_train_batch, y_pred=fcn_logits)\n",
        "    fcn_PerClassIOUMetric.update_state(y_true=y_train_batch, y_pred=fcn_logits)\n",
        "    fcn_Dice_Coefficent_matrics.update_state(y_train_batch, fcn_logits)\n",
        "    fcn_PerClassDiceCoefficientMatrics.update_state(y_train_batch, fcn_logits)\n",
        "    fcn_Pixel_accurcy_metrics.update_state(y_train_batch, fcn_logits)\n",
        "\n",
        "    unet_IOUMetric.update_state(y_true=y_train_batch, y_pred=unet_logits)\n",
        "    unet_PerClassIOUMetric.update_state(y_true=y_train_batch, y_pred=unet_logits)\n",
        "    unet_Dice_Coefficent_matrics.update_state(y_train_batch, unet_logits)\n",
        "    unet_PerClassDiceCoefficientMatrics.update_state(y_train_batch, unet_logits)\n",
        "    unet_Pixel_accurcy_metrics.update_state(y_train_batch, unet_logits)\n",
        "\n",
        "    unet_plus_plus_IOUMetric.update_state(y_true=y_train_batch, y_pred=unet_plus_plus_logits)\n",
        "    unet_plus_plus_PerClassIOUMetric.update_state(y_true=y_train_batch, y_pred=unet_plus_plus_logits)\n",
        "    unet_plus_plus_Dice_Coefficent_matrics.update_state(y_train_batch, unet_plus_plus_logits)\n",
        "    unet_plus_plus_PerClassDiceCoefficientMatrics.update_state(y_train_batch, unet_plus_plus_logits)\n",
        "    unet_plus_plus_Pixel_accurcy_metrics.update_state(y_train_batch, unet_plus_plus_logits)\n",
        "\n",
        "    del tape\n",
        "    return {\n",
        "      'fcn_loss': fcn_loss,\n",
        "      'unet_loss': unet_loss,\n",
        "      'unet_plus_plus_loss' : unet_plus_plus_loss\n",
        "\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pszZ4wUGUJQZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Soyc3vECf0V"
      },
      "outputs": [],
      "source": [
        "# with strategy.scope():\n",
        "#   # @tf.function\n",
        "#   def fcn_train_step(data):\n",
        "#     x_train_batch , y_train_batch = data\n",
        "#     with tf.GradientTape() as tape  :\n",
        "#       tf.print('train step begaines')\n",
        "#       tf.print(\"Input batch shape:\", tf.shape(x_train_batch), \"Label shape:\", tf.shape(y_train_batch))\n",
        "#       fcn_logits = fcn(x_train_batch)\n",
        "#       tf.print(\"Logits computed, shape:\", tf.shape(fcn_logits))\n",
        "#       # tf.debugging.check_numerics(fcn_logits, \"Logits have NaN or Inf\")\n",
        "#       per_example_loss = fcn_SemanticSegmentationLoss.compute_per_sample(y_train_batch, fcn_logits)\n",
        "#       loss = tf.nn.compute_average_loss(\n",
        "#             per_example_loss,\n",
        "#             global_batch_size=8)\n",
        "#       tf.print(\"Loss computed:\", loss)\n",
        "#       # tf.debugging.check_numerics(fcn_loss, \"Loss is NaN or Inf\")\n",
        "#     fcn_gradients=tape.gradient(loss  , fcn.trainable_variables)\n",
        "#     # fcn_gradients = [tf.clip_by_value(g, -0.5, 0.5) if g is not None else g for g in fcn_gradients]\n",
        "#     # optimizer_fcn.apply_gradients(zip(fcn_gradients,fcn.trainable_variables))\n",
        "#     # tf.print('this fcn loss at fcn', fcn_loss)\n",
        "#     # fcn_IOUMetric.update_state(y_true=y_train_batch, y_pred=fcn_logits)\n",
        "#     # fcn_PerClassIOUMetric.update_state(y_true=y_train_batch, y_pred=fcn_logits)\n",
        "#     # fcn_Dice_Coefficent_matrics.update_state(y_train_batch, fcn_logits)\n",
        "#     # fcn_PerClassDiceCoefficientMatrics.update_state(y_train_batch, fcn_logits)\n",
        "#     # fcn_Pixel_accurcy_metrics.update_state(y_train_batch, fcn_logits)\n",
        "#     # tf.print(f'fcn loss : {fcn_loss}')\n",
        "#     # del fcn_logits\n",
        "#     # del fcn_gradients\n",
        "\n",
        "#     return loss\n",
        "\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "  # @tf.function\n",
        "    def train_step(dist_inputs):\n",
        "        x_train, y_train = dist_inputs\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = fcn(x_train)\n",
        "\n",
        "            per_example_loss = fcn_SemanticSegmentationLoss.compute_per_sample(y_train, logits)\n",
        "            loss = tf.nn.compute_average_loss(\n",
        "            per_example_loss,\n",
        "            global_batch_size=final_batch_size\n",
        "        )\n",
        "\n",
        "        gradients = tape.gradient(loss, fcn.trainable_variables)\n",
        "        optimizer_fcn.apply_gradients(zip(gradients,fcn.trainable_variables))\n",
        "\n",
        "\n",
        "        y_train = tf.squeeze(y_train , axis = -1)\n",
        "\n",
        "        fcn_IOUMetric.update_state(y_true=y_train, y_pred=logits)\n",
        "        fcn_PerClassIOUMetric.update_state(y_true=y_train, y_pred=logits)\n",
        "        fcn_Dice_Coefficent_matrics.update_state(y_train, logits)\n",
        "        fcn_PerClassDiceCoefficientMatrics.update_state(y_train, logits)\n",
        "        fcn_Pixel_accurcy_metrics.update_state(y_train, logits)\n",
        "\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1Q331l9EVja"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  @tf.function\n",
        "  def unet_train_step(x_train_batch , y_train_batch) :\n",
        "    with tf.GradientTape() as tape :\n",
        "      unet_logits = unet(x_train_batch)\n",
        "      unet_loss = unet_SemanticSegmentationLoss(y_true=y_train_batch, y_pred=unet_logits)\n",
        "    unet_gradients = tape.gradient(unet_loss , unet.trainable_variables)\n",
        "    optimizer_unet.apply_gradients(zip(unet_gradients,unet.trainable_variables))\n",
        "\n",
        "    unet_IOUMetric.update_state(y_true=y_train_batch, y_pred=unet_logits)\n",
        "    unet_PerClassIOUMetric.update_state(y_true=y_train_batch, y_pred=unet_logits)\n",
        "    unet_Dice_Coefficent_matrics.update_state(y_train_batch, unet_logits)\n",
        "    unet_PerClassDiceCoefficientMatrics.update_state(y_train_batch, unet_logits)\n",
        "    unet_Pixel_accurcy_metrics.update_state(y_train_batch, unet_logits)\n",
        "\n",
        "    del unet_logits\n",
        "    del unet_gradients\n",
        "    return unet_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWMXg-_JFho9"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  # @tf.function\n",
        "  def unet_plus_plus_train_step(dist_inputs):\n",
        "    x_train, y_train = dist_inputs\n",
        "    with tf.GradientTape() as tape :\n",
        "      unet_plus_plus_outputs = unet_plus_plus(x_train)\n",
        "      per_example_loss = deepSupervisionLoss.compute_per_sample(y_train, unet_plus_plus_outputs)\n",
        "      unet_plus_plus_logits = unet_plus_plus_outputs[-1]\n",
        "      loss = tf.nn.compute_average_loss(\n",
        "            per_example_loss,\n",
        "            global_batch_size=final_batch_size\n",
        "      )\n",
        "\n",
        "    unet_plus_plus_gradients = tape.gradient(loss, unet_plus_plus.trainable_variables)\n",
        "    optimizer_unet_plus_plus.apply_gradients(zip(unet_plus_plus_gradients , unet_plus_plus.trainable_variables))\n",
        "\n",
        "    y_train = tf.squeeze(y_train , axis = -1)\n",
        "\n",
        "    unet_plus_plus_IOUMetric.update_state(y_true=y_train, y_pred=unet_plus_plus_logits)\n",
        "    unet_plus_plus_PerClassIOUMetric.update_state(y_true=y_train, y_pred=unet_plus_plus_logits)\n",
        "    unet_plus_plus_Dice_Coefficent_matrics.update_state(y_train, unet_plus_plus_logits)\n",
        "    unet_plus_plus_PerClassDiceCoefficientMatrics.update_state(y_train, unet_plus_plus_logits)\n",
        "    unet_plus_plus_Pixel_accurcy_metrics.update_state(y_train, unet_plus_plus_logits)\n",
        "\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCgVkQwLZeyT"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  @tf.function\n",
        "  def val_step(x_val_batch,y_val_batch):\n",
        "    fcn_logits = fcn(x_val_batch)\n",
        "    fcn_val_loss = fcn_SemanticSegmentationLoss(y_true=y_val_batch,y_pred=fcn_logits)\n",
        "    unet_logits  = unet(x_val_batch)\n",
        "    unet_val_loss = unet_SemanticSegmentationLoss(y_true = y_val_batch,y_pred = unet_logits)\n",
        "    unet_plus_plus_logits = unet_plus_plus(x_val_batch)\n",
        "    unet_plus_plus_val_loss = deepSupervisionLoss(y_true = y_val_batch, y_pred = unet_plus_plus_logits)\n",
        "\n",
        "    fcn_IOUMetric_val.update_state(y_true=y_val_batch, y_pred=fcn_logits)\n",
        "    fcn_PerClassIOUMetric_val.update_state(y_true=y_val_batch, y_pred=fcn_logits)\n",
        "    fcn_Dice_Coefficent_matrics_val.update_state(y_val_batch, fcn_logits)\n",
        "    fcn_PerClassDiceCoefficientMatrics_val.update_state(y_val_batch, fcn_logits)\n",
        "    fcn_Pixel_accurcy_metrics_val.update_state(y_val_batch, fcn_logits)\n",
        "\n",
        "    unet_IOUMetric_val.update_state(y_true=y_val_batch, y_pred=unet_logits)\n",
        "    unet_PerClassIOUMetric_val.update_state(y_true=y_val_batch, y_pred=unet_logits)\n",
        "    unet_Dice_Coefficent_matrics_val.update_state(y_val_batch, unet_logits)\n",
        "    unet_PerClassDiceCoefficientMatrics_val.update_state(y_val_batch, unet_logits)\n",
        "    unet_Pixel_accurcy_metrics_val.update_state(y_val_batch, unet_logits)\n",
        "\n",
        "    unet_plus_plus_IOUMetric_val.update_state(y_true=y_val_batch, y_pred=unet_plus_plus_logits)\n",
        "    unet_plus_plus_PerClassIOUMetric_val.update_state(y_true=y_val_batch, y_pred=unet_plus_plus_logits)\n",
        "    unet_plus_plus_Dice_Coefficent_matrics_val.update_state(y_val_batch, unet_plus_plus_logits)\n",
        "    unet_plus_plus_PerClassDiceCoefficientMatrics_val.update_state(y_val_batch, unet_plus_plus_logits)\n",
        "    unet_plus_plus_Pixel_accurcy_metrics_val.update_state(y_val_batch, unet_plus_plus_logits)\n",
        "    return {\n",
        "        'fcn_val_loss' : fcn_val_loss ,\n",
        "        'unet_val_loss' : unet_val_loss ,\n",
        "        'unet_plus_plus_val_loss' : unet_plus_plus_val_loss\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7Gd9o_RG-AD"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "  @tf.function\n",
        "  def fcn_val_step(data  ):\n",
        "    x_val_batch , y_val_batch = data\n",
        "    logits = fcn(x_val_batch)\n",
        "\n",
        "    per_example_loss = fcn_SemanticSegmentationLoss.compute_per_sample(y_val_batch, logits)\n",
        "    loss = tf.nn.compute_average_loss(\n",
        "            per_example_loss,\n",
        "            global_batch_size=16)\n",
        "\n",
        "    y_val_batch = tf.squeeze(y_val_batch, axis = -1)\n",
        "\n",
        "    fcn_IOUMetric_val.update_state(y_true=y_val_batch, y_pred=logits)\n",
        "    fcn_PerClassIOUMetric_val.update_state(y_true=y_val_batch, y_pred=logits)\n",
        "    fcn_Dice_Coefficent_matrics_val.update_state(y_val_batch, logits)\n",
        "    fcn_PerClassDiceCoefficientMatrics_val.update_state(y_val_batch, logits)\n",
        "    fcn_Pixel_accurcy_metrics_val.update_state(y_val_batch, logits)\n",
        "\n",
        "    del logits\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gPYJjZUIMIa"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "\n",
        "  def unet_val_step (x_val_batch , y_val_batch) :\n",
        "    unet_logits = unet(x_val_batch)\n",
        "    unet_val_loss = unet_SemanticSegmentationLoss(y_true = y_val_batch,y_pred = unet_logits)\n",
        "\n",
        "    unet_IOUMetric_val.update_state(y_true=y_val_batch, y_pred=unet_logits)\n",
        "    unet_PerClassIOUMetric_val.update_state(y_true=y_val_batch, y_pred=unet_logits)\n",
        "    unet_Dice_Coefficent_matrics_val.update_state(y_val_batch, unet_logits)\n",
        "    unet_PerClassDiceCoefficientMatrics_val.update_state(y_val_batch, unet_logits)\n",
        "    unet_Pixel_accurcy_metrics_val.update_state(y_val_batch, unet_logits)\n",
        "\n",
        "    del unet_logits\n",
        "    return unet_val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOhoWJ7YIu-J"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "\n",
        "  def unet_plus_plus_val_step(data) :\n",
        "    x_val_batch , y_val_batch = data\n",
        "    unet_plus_plus_outputs = unet_plus_plus(x_val_batch)\n",
        "    per_example_loss = deepSupervisionLoss.compute_per_sample( y_val_batch,  unet_plus_plus_outputs)\n",
        "    unet_plus_plus_logits = unet_plus_plus_outputs[-1]\n",
        "    loss = tf.nn.compute_average_loss(\n",
        "            per_example_loss,\n",
        "            global_batch_size=16)\n",
        "\n",
        "    y_val_batch = tf.squeeze(y_val_batch, axis = -1)\n",
        "\n",
        "    unet_plus_plus_IOUMetric_val.update_state(y_true=y_val_batch, y_pred=unet_plus_plus_logits)\n",
        "    unet_plus_plus_PerClassIOUMetric_val.update_state(y_true=y_val_batch, y_pred=unet_plus_plus_logits)\n",
        "    unet_plus_plus_Dice_Coefficent_matrics_val.update_state(y_val_batch, unet_plus_plus_logits)\n",
        "    unet_plus_plus_PerClassDiceCoefficientMatrics_val.update_state(y_val_batch, unet_plus_plus_logits)\n",
        "    unet_plus_plus_Pixel_accurcy_metrics_val.update_state(y_val_batch, unet_plus_plus_logits)\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u90A1zGJ3rhE"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "  @tf.function\n",
        "  def distributed_train_step(x_train_batch , y_train_batch):\n",
        "    print('distributed_train_step start')\n",
        "    per_replica_results = strategy.run(train_step, args=(x_train_batch, y_train_batch))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    fcn_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['fcn_loss'],axis=None)\n",
        "    unet_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['unet_loss'],axis=None)\n",
        "    unet_plus_plus_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['unet_plus_plus_loss'],axis = None)\n",
        "    print('distributed train step end ')\n",
        "    return {\n",
        "        'fcn' : fcn_loss ,\n",
        "        'unet' : unet_loss ,\n",
        "        'unet_plus_plus' : unet_plus_plus_loss\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phYK15qPKPuw"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    @tf.function\n",
        "    def fcn_distributed_train_step(dist_data):\n",
        "        per_replica_loss = strategy.run(train_step, args=(dist_data,))\n",
        "\n",
        "        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vBuQHyFK8GH"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "  @tf.function\n",
        "  def unet_distributed_train_step(x_train_batch , y_train_batch) :\n",
        "    per_replica_loss =strategy.run(unet_train_step , args = (x_train_batch , y_train_batch ) )\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.MEAN  , per_replica_loss , axis = None )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eU7axuiNLE9O"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "  @tf.function\n",
        "  def unet_plus_plus_distributed_train_step(dist_data) :\n",
        "    per_replica_loss =strategy.run(unet_plus_plus_train_step , args = (dist_data, ) )\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.SUM  , per_replica_loss , axis = None )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJIzbVN0Wcnc"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "  @tf.function\n",
        "  def distributed_val_step(x_val_batch,y_val_batch):\n",
        "    per_replica_results = strategy.run(val_step , args = (x_val_batch,y_val_batch))\n",
        "    fcn_val_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['fcn_val_loss'] , axis = None)\n",
        "    unet_val_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['unet_val_loss'] , axis = None)\n",
        "    unet_plus_plus_val_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN,per_replica_results['unet_plus_plus_val_loss'] , axis = None)\n",
        "    return {\n",
        "        'fcn' : fcn_val_loss ,\n",
        "        'unet' : unet_val_loss ,\n",
        "        'unet_plus_plus' : unet_plus_plus_val_loss\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN48XOyeLRRm"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    @tf.function\n",
        "    def fcn_distributed_val_step(dist_data):\n",
        "        per_replica_loss = strategy.run(fcn_val_step, args=(dist_data,))\n",
        "\n",
        "        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLVb4GtWMdgu"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "  @tf.function\n",
        "  def unet_distributed_val_step( data) :\n",
        "    per_replica_loss =strategy.run(unet_val_step , args = (data  ) )\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.MEAN  , per_replica_loss , axis = None )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R164kA-dN1gc"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "  @tf.function\n",
        "  def unet_plus_plus_distributed_val_step(dist_data) :\n",
        "    per_replica_loss =strategy.run(unet_plus_plus_val_step , args = (dist_data, ) )\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.SUM  , per_replica_loss , axis = None )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8Iz61nAft5x"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "\n",
        "  def train_fcn_for_one_epoch(epoch):\n",
        "    losses = []\n",
        "    step = 1\n",
        "    for  data1 in  (train_dataset):\n",
        "\n",
        "      fcn_loss=fcn_distributed_train_step(data1)\n",
        "\n",
        "      losses.append(fcn_loss)\n",
        "\n",
        "      data = {\n",
        "\n",
        "              'loss' : fcn_loss ,\n",
        "              'metrics': {\n",
        "                  'IOUMetric' : fcn_IOUMetric.result(),\n",
        "                  'PerClassIOUMetric' : fcn_PerClassIOUMetric.result(),\n",
        "                  'Dice_Coefficent_matrics' : fcn_Dice_Coefficent_matrics.result(),\n",
        "                  'PerClassDiceCoefficientMatrics' : fcn_PerClassDiceCoefficientMatrics.result() ,\n",
        "                  'Pixel_accurcy_metrics' : fcn_Pixel_accurcy_metrics.result()\n",
        "              }\n",
        "\n",
        "\n",
        "      }\n",
        "      fcn_master_callback.on_batch_end(batch = step , epoch = epoch,data = data)\n",
        "      step +=1\n",
        "    return losses\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0AhtXv6yh3A"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "\n",
        "  def train_unet_for_one_epoch(epoch):\n",
        "    losss = []\n",
        "    step = 1\n",
        "    for  (x_train_batch , y_train_batch) in  (train_dataset):\n",
        "      unet_loss=unet_distributed_train_step(x_train_batch , y_train_batch)\n",
        "\n",
        "      losss.append(unet_loss)\n",
        "\n",
        "      data = {\n",
        "\n",
        "              'loss' : unet_loss ,\n",
        "              'metrics': {\n",
        "                  'IOUMetric' : fcn_IOUMetric.result(),\n",
        "                  'PerClassIOUMetric' : fcn_PerClassIOUMetric.result(),\n",
        "                  'Dice_Coefficent_matrics' : fcn_Dice_Coefficent_matrics.result(),\n",
        "                  'PerClassDiceCoefficientMatrics' : fcn_PerClassDiceCoefficientMatrics.result() ,\n",
        "                  'Pixel_accurcy_metrics' : fcn_Pixel_accurcy_metrics.result()\n",
        "              }\n",
        "\n",
        "\n",
        "      }\n",
        "      unet_master_callback.on_batch_end(batch = step , epoch = epoch,data = data)\n",
        "      step +=1\n",
        "    return losses\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyZT7CIOyijC"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "\n",
        "  def train_unet_plus_plus_for_one_epoch(epoch):\n",
        "    losss = []\n",
        "    step = 1\n",
        "    for  data1 in  (train_dataset):\n",
        "\n",
        "      unet_plus_plus_loss=unet_plus_plus_distributed_train_step(data1)\n",
        "\n",
        "      losss.append(unet_plus_plus_loss)\n",
        "\n",
        "      data = {\n",
        "\n",
        "              'loss' : unet_plus_plus_loss ,\n",
        "              'metrics': {\n",
        "                  'IOUMetric' : unet_plus_plus_IOUMetric.result(),\n",
        "                  'PerClassIOUMetric' : unet_plus_plus_PerClassIOUMetric.result(),\n",
        "                  'Dice_Coefficent_matrics' : unet_plus_plus_Dice_Coefficent_matrics.result(),\n",
        "                  'PerClassDiceCoefficientMatrics' : unet_plus_plus_PerClassDiceCoefficientMatrics.result() ,\n",
        "                  'Pixel_accurcy_metrics' : unet_plus_plus_Pixel_accurcy_metrics.result()\n",
        "              }\n",
        "\n",
        "\n",
        "      }\n",
        "      unet_plus_plus_master_callback.on_batch_end(batch = step , epoch = epoch,data = data)\n",
        "      step +=1\n",
        "    return losss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTN0SW90VJ3m"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "\n",
        "  def val_fcn_for_one_epoch():\n",
        "    val_losses = []\n",
        "    step = 1\n",
        "    for  dist_data in (val_dataset):\n",
        "      fcn_val_loss = fcn_distributed_val_step(dist_data)\n",
        "      val_losses.append(fcn_val_loss)\n",
        "\n",
        "    return val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GARHD0UzoUw"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "  @tf.function\n",
        "  def val_unet_for_one_epoch():\n",
        "    val_losses = []\n",
        "    step = 1\n",
        "    for  dist_data in (val_dataset):\n",
        "      unet_val_loss = unet_distributed_val_step(dist_data)\n",
        "\n",
        "      val_losses.append(unet_val_loss)\n",
        "\n",
        "    return val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmR97KQLzpGR"
      },
      "outputs": [],
      "source": [
        "with strategy.scope() :\n",
        "  # @tf.function\n",
        "  def val_unet_plus_plus_for_one_epoch():\n",
        "    val_losses = []\n",
        "    step = 1\n",
        "    for  dist_data in (val_dataset):\n",
        "      unet_plus_plus_val_loss = unet_plus_plus_distributed_val_step(dist_data)\n",
        "\n",
        "      val_losses.append(unet_plus_plus_val_loss)\n",
        "\n",
        "    return val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ1N4vCPjoua"
      },
      "outputs": [],
      "source": [
        "fcn.Encoder.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "fcq-4mHrBoZB",
        "outputId": "9b81fb6c-eb6f-41d6-fe16-33579290236f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no checkpoint found starting from epoch 1\n",
            "Epoch begins : 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "epoch 1:   0%|          | 0/47 [00:14<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h3>📊 Batch-wise Loss Table</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-d98465d9d00f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfcn_master_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fcn_for_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_fcn_for_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-6459191aa372>\u001b[0m in \u001b[0;36mtrain_fcn_for_one_epoch\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m  \u001b[0mdata1\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mfcn_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcn_distributed_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36mget_next\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_get_next_as_optional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_no_partial_batch_handling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0moptional_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m_get_next_no_partial_batch_handling\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;31m# Make `replicas` a flat list of values across all replicas.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0mreplicas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_as_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replica_order\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36mget_next_as_list\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1425\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_data_list_with_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_next_as_optional_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py\u001b[0m in \u001b[0;36mget_next\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_iterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mget_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_next_as_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    777\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3079\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3082\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3083\u001b[0m         \"output_shapes\", output_shapes)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  stop_training =False\n",
        "  start=fcn_master_callback.on_train_begin()\n",
        "  for epoch in range(start , 250 ):\n",
        "    fcn_master_callback.on_epoch_begin(epoch)\n",
        "    losses = train_fcn_for_one_epoch(epoch)\n",
        "    val_losses = val_fcn_for_one_epoch()\n",
        "    avg_loss = tf.reduce_mean(losses)\n",
        "    avg_val_loss = tf.reduce_mean(val_losses)\n",
        "    data = {\n",
        "\n",
        "                'loss' : avg_loss ,\n",
        "                'val_loss' : avg_val_loss ,\n",
        "                'metrics': {\n",
        "                    'IOUMetric' : fcn_IOUMetric.result(),\n",
        "                    'PerClassIOUMetric' : fcn_PerClassIOUMetric.result(),\n",
        "                    'Dice_Coefficent_matrics' : fcn_Dice_Coefficent_matrics.result(),\n",
        "                    'PerClassDiceCoefficientMatrics' : fcn_PerClassDiceCoefficientMatrics.result() ,\n",
        "                    'Pixel_accurcy_metrics' : fcn_Pixel_accurcy_metrics.result(),\n",
        "\n",
        "                    'IOUMetric_val' : fcn_IOUMetric_val.result(),\n",
        "                    'PerClassIOUMetric_val' : fcn_PerClassIOUMetric_val.result(),\n",
        "                    'Dice_Coefficent_matrics_val' : fcn_Dice_Coefficent_matrics_val.result(),\n",
        "                    'PerClassDiceCoefficientMatrics_val' : fcn_PerClassDiceCoefficientMatrics_val.result() ,\n",
        "                    'Pixel_accurcy_metrics_val' : fcn_Pixel_accurcy_metrics_val.result()\n",
        "\n",
        "            },\n",
        "        }\n",
        "    fcn_IOUMetric.reset_state()\n",
        "    fcn_IOUMetric_val.reset_state()\n",
        "    fcn_PerClassIOUMetric.reset_state()\n",
        "    fcn_PerClassIOUMetric_val.reset_state()\n",
        "    fcn_Dice_Coefficent_matrics.reset_state()\n",
        "    fcn_Dice_Coefficent_matrics_val.reset_state()\n",
        "    fcn_PerClassDiceCoefficientMatrics.reset_state()\n",
        "    fcn_PerClassDiceCoefficientMatrics_val.reset_state()\n",
        "    fcn_Pixel_accurcy_metrics.reset_state()\n",
        "    fcn_Pixel_accurcy_metrics_val.reset_state()\n",
        "\n",
        "\n",
        "\n",
        "    stop_training=fcn_master_callback.on_epoch_end(epoch=epoch , data= data)\n",
        "    if stop_training :\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkMcZwBqAajg"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  stop_training =False\n",
        "  start=unet_master_callback.on_train_begin()\n",
        "  for epoch in range(start , 250 ):\n",
        "    unet_master_callback.on_epoch_begin(epoch)\n",
        "    losses = train_unet_for_one_epoch(epoch)\n",
        "    val_losses = val_unet_for_one_epoch()\n",
        "    data = {\n",
        "\n",
        "                'loss' : losses ,\n",
        "                'val_loss' : val_losses ,\n",
        "                'metrics': {\n",
        "                    'IOUMetric' : unet_IOUMetric.result(),\n",
        "                    'PerClassIOUMetric' : unet_PerClassIOUMetric.result(),\n",
        "                    'Dice_Coefficent_matrics' : unet_Dice_Coefficent_matrics.result(),\n",
        "                    'PerClassDiceCoefficientMatrics' : unet_PerClassDiceCoefficientMatrics.result() ,\n",
        "                    'Pixel_accurcy_metrics' : unet_Pixel_accurcy_metrics.result(),\n",
        "\n",
        "                    'IOUMetric_val' : unet_IOUMetric_val.result(),\n",
        "                    'PerClassIOUMetric_val' : unet_PerClassIOUMetric_val.result(),\n",
        "                    'Dice_Coefficent_matrics_val' : unet_Dice_Coefficent_matrics_val.result(),\n",
        "                    'PerClassDiceCoefficientMatrics_val' : unet_PerClassDiceCoefficientMatrics_val.result() ,\n",
        "                    'Pixel_accurcy_metrics_val' : unet_Pixel_accurcy_metrics_val.result()\n",
        "\n",
        "            },\n",
        "        }\n",
        "    unet_IOUMetric.reset_state()\n",
        "    unet_IOUMetric_val.reset_state()\n",
        "    unet_PerClassIOUMetric.reset_state()\n",
        "    unet_PerClassIOUMetric_val.reset_state()\n",
        "    unet_Dice_Coefficent_matrics.reset_state()\n",
        "    unet_Dice_Coefficent_matrics_val.reset_state()\n",
        "    unet_PerClassDiceCoefficientMatrics.reset_state()\n",
        "    unet_PerClassDiceCoefficientMatrics_val.reset_state()\n",
        "    unet_Pixel_accurcy_metrics.reset_state()\n",
        "    unet_Pixel_accurcy_metrics_val.reset_state()\n",
        "\n",
        "\n",
        "\n",
        "    stop_training=unet_master_callback.on_epoch_end(epoch=epoch , data= data)\n",
        "    if stop_training :\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unet_plus_plus.encoder.backbone.trainable = True"
      ],
      "metadata": {
        "id": "iDPsuXpG4tKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hocvJL_Do4Gk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc8ba90c-5374-4f17-a49a-acd5764b8bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored from checkpoint: /content/drive/MyDrive/CityScapes_model_checkpoints/unet_plus_plus_new/ckpt-16, resuming from epoch 16\n",
            "Epoch begins : 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\repoch 16:   0%|          | 0/372 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h3>📊 Batch-wise Loss Table</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.172\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.173\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.174\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.175\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.178\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.179\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.180\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.181\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.184\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.185\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.186\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.187\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.190\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.191\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.192\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.193\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.196\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.197\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.198\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.199\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.202\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.203\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.204\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.205\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.208\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.209\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.210\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.211\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.214\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.215\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.216\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.217\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.220\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.221\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.222\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.223\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.226\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.227\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.228\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.229\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.232\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.233\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.234\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.235\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.238\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.239\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.240\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._trainable_variables.241\n",
            "epoch 16:   0%|          | 1/372 [05:12<32:10:03, 312.14s/it, epoch :16 , batch =0.00269]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    batch                                           loss  \\\n",
              "0       1  tf.Tensor(2.9772024, shape=(), dtype=float32)   \n",
              "1       2  tf.Tensor(2.0697846, shape=(), dtype=float32)   \n",
              "2       3  tf.Tensor(2.3200378, shape=(), dtype=float32)   \n",
              "3       4  tf.Tensor(1.9559888, shape=(), dtype=float32)   \n",
              "4       5  tf.Tensor(1.8304383, shape=(), dtype=float32)   \n",
              "5       6  tf.Tensor(2.0613914, shape=(), dtype=float32)   \n",
              "6       7  tf.Tensor(1.7585846, shape=(), dtype=float32)   \n",
              "7       8  tf.Tensor(1.6805964, shape=(), dtype=float32)   \n",
              "8       9  tf.Tensor(1.7796936, shape=(), dtype=float32)   \n",
              "9      10   tf.Tensor(2.805642, shape=(), dtype=float32)   \n",
              "10     11  tf.Tensor(1.7449969, shape=(), dtype=float32)   \n",
              "11     12  tf.Tensor(1.7753152, shape=(), dtype=float32)   \n",
              "12     13  tf.Tensor(1.6673106, shape=(), dtype=float32)   \n",
              "13     14  tf.Tensor(1.8188568, shape=(), dtype=float32)   \n",
              "14     15  tf.Tensor(1.5375295, shape=(), dtype=float32)   \n",
              "15     16  tf.Tensor(1.7217672, shape=(), dtype=float32)   \n",
              "16     17  tf.Tensor(1.5391448, shape=(), dtype=float32)   \n",
              "17     18  tf.Tensor(1.6540797, shape=(), dtype=float32)   \n",
              "18     19  tf.Tensor(1.7460576, shape=(), dtype=float32)   \n",
              "19     20  tf.Tensor(1.8060933, shape=(), dtype=float32)   \n",
              "20     21  tf.Tensor(1.6248932, shape=(), dtype=float32)   \n",
              "21     22  tf.Tensor(1.6330991, shape=(), dtype=float32)   \n",
              "22     23  tf.Tensor(1.5954661, shape=(), dtype=float32)   \n",
              "23     24   tf.Tensor(1.553469, shape=(), dtype=float32)   \n",
              "24     25  tf.Tensor(1.5998348, shape=(), dtype=float32)   \n",
              "25     26  tf.Tensor(1.5501672, shape=(), dtype=float32)   \n",
              "26     27  tf.Tensor(2.3542838, shape=(), dtype=float32)   \n",
              "27     28   tf.Tensor(1.665332, shape=(), dtype=float32)   \n",
              "\n",
              "                                          IOUMetric  \\\n",
              "0   tf.Tensor(0.110013746, shape=(), dtype=float32)   \n",
              "1   tf.Tensor(0.062283497, shape=(), dtype=float32)   \n",
              "2    tf.Tensor(0.06282784, shape=(), dtype=float32)   \n",
              "3    tf.Tensor(0.06288457, shape=(), dtype=float32)   \n",
              "4    tf.Tensor(0.06289239, shape=(), dtype=float32)   \n",
              "5    tf.Tensor(0.06289317, shape=(), dtype=float32)   \n",
              "6    tf.Tensor(0.06289329, shape=(), dtype=float32)   \n",
              "7     tf.Tensor(0.0628933, shape=(), dtype=float32)   \n",
              "8     tf.Tensor(0.0628933, shape=(), dtype=float32)   \n",
              "9     tf.Tensor(0.0628933, shape=(), dtype=float32)   \n",
              "10    tf.Tensor(0.0628933, shape=(), dtype=float32)   \n",
              "11  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "12  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "13  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "14  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "15  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "16  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "17  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "18  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "19  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "20  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "21  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "22  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "23  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "24  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "25  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "26  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "27  tf.Tensor(0.010261722, shape=(), dtype=float32)   \n",
              "\n",
              "                                    PerClassIOUMetric  \\\n",
              "0   (tf.Tensor(0.0079498, shape=(), dtype=float32)...   \n",
              "1   (tf.Tensor(0.10319814, shape=(), dtype=float32...   \n",
              "2   (tf.Tensor(0.10188899, shape=(), dtype=float32...   \n",
              "3   (tf.Tensor(0.10301771, shape=(), dtype=float32...   \n",
              "4   (tf.Tensor(0.103173494, shape=(), dtype=float3...   \n",
              "5   (tf.Tensor(0.10318901, shape=(), dtype=float32...   \n",
              "6   (tf.Tensor(0.103191376, shape=(), dtype=float3...   \n",
              "7   (tf.Tensor(0.103191644, shape=(), dtype=float3...   \n",
              "8   (tf.Tensor(0.10319165, shape=(), dtype=float32...   \n",
              "9   (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "10  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "11  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "12  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "13  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "14  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "15  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "16  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "17  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "18  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "19  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "20  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "21  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "22  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "23  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "24  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "25  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "26  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "27  (tf.Tensor(0.10319166, shape=(), dtype=float32...   \n",
              "\n",
              "                           Dice_Coefficent_matrics  \\\n",
              "0    tf.Tensor(0.3176492, shape=(), dtype=float32)   \n",
              "1    tf.Tensor(0.3289221, shape=(), dtype=float32)   \n",
              "2    tf.Tensor(0.3293653, shape=(), dtype=float32)   \n",
              "3   tf.Tensor(0.32953003, shape=(), dtype=float32)   \n",
              "4   tf.Tensor(0.32954675, shape=(), dtype=float32)   \n",
              "5   tf.Tensor(0.32954854, shape=(), dtype=float32)   \n",
              "6    tf.Tensor(0.3295489, shape=(), dtype=float32)   \n",
              "7   tf.Tensor(0.32954893, shape=(), dtype=float32)   \n",
              "8   tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "9   tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "10  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "11  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "12  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "13  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "14  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "15  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "16  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "17  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "18  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "19  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "20  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "21  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "22  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "23  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "24  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "25  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "26  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "27  tf.Tensor(0.32954895, shape=(), dtype=float32)   \n",
              "\n",
              "                       PerClassDiceCoefficientMatrics  \\\n",
              "0   (tf.Tensor(0.0157742, shape=(), dtype=float32)...   \n",
              "1   (tf.Tensor(0.18708904, shape=(), dtype=float32...   \n",
              "2   (tf.Tensor(0.18493512, shape=(), dtype=float32...   \n",
              "3   (tf.Tensor(0.18679248, shape=(), dtype=float32...   \n",
              "4   (tf.Tensor(0.18704852, shape=(), dtype=float32...   \n",
              "5   (tf.Tensor(0.18707399, shape=(), dtype=float32...   \n",
              "6   (tf.Tensor(0.18707788, shape=(), dtype=float32...   \n",
              "7   (tf.Tensor(0.18707833, shape=(), dtype=float32...   \n",
              "8   (tf.Tensor(0.18707834, shape=(), dtype=float32...   \n",
              "9   (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "10  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "11  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "12  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "13  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "14  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "15  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "16  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "17  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "18  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "19  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "20  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "21  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "22  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "23  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "24  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "25  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "26  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "27  (tf.Tensor(0.18707836, shape=(), dtype=float32...   \n",
              "\n",
              "                              Pixel_accurcy_metrics  \n",
              "0   tf.Tensor(0.044201747, shape=(), dtype=float32)  \n",
              "1   tf.Tensor(0.085916825, shape=(), dtype=float32)  \n",
              "2   tf.Tensor(0.087906584, shape=(), dtype=float32)  \n",
              "3    tf.Tensor(0.08847301, shape=(), dtype=float32)  \n",
              "4    tf.Tensor(0.08855101, shape=(), dtype=float32)  \n",
              "5   tf.Tensor(0.088558845, shape=(), dtype=float32)  \n",
              "6    tf.Tensor(0.08856004, shape=(), dtype=float32)  \n",
              "7    tf.Tensor(0.08856017, shape=(), dtype=float32)  \n",
              "8    tf.Tensor(0.08856018, shape=(), dtype=float32)  \n",
              "9    tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "10   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "11   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "12   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "13   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "14   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "15   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "16   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "17   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "18   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "19   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "20   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "21   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "22   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "23   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "24   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "25   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "26   tf.Tensor(0.08856019, shape=(), dtype=float32)  \n",
              "27   tf.Tensor(0.08856019, shape=(), dtype=float32)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5b83586-0595-48aa-b8b8-697680cf8baf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch</th>\n",
              "      <th>loss</th>\n",
              "      <th>IOUMetric</th>\n",
              "      <th>PerClassIOUMetric</th>\n",
              "      <th>Dice_Coefficent_matrics</th>\n",
              "      <th>PerClassDiceCoefficientMatrics</th>\n",
              "      <th>Pixel_accurcy_metrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>tf.Tensor(2.9772024, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.110013746, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.0079498, shape=(), dtype=float32)...</td>\n",
              "      <td>tf.Tensor(0.3176492, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.0157742, shape=(), dtype=float32)...</td>\n",
              "      <td>tf.Tensor(0.044201747, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>tf.Tensor(2.0697846, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.062283497, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319814, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.3289221, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18708904, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.085916825, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>tf.Tensor(2.3200378, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.06282784, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10188899, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.3293653, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18493512, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.087906584, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>tf.Tensor(1.9559888, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.06288457, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10301771, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32953003, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18679248, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08847301, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>tf.Tensor(1.8304383, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.06289239, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.103173494, shape=(), dtype=float3...</td>\n",
              "      <td>tf.Tensor(0.32954675, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18704852, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08855101, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>tf.Tensor(2.0613914, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.06289317, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10318901, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954854, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707399, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.088558845, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>tf.Tensor(1.7585846, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.06289329, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.103191376, shape=(), dtype=float3...</td>\n",
              "      <td>tf.Tensor(0.3295489, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707788, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856004, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>tf.Tensor(1.6805964, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.0628933, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.103191644, shape=(), dtype=float3...</td>\n",
              "      <td>tf.Tensor(0.32954893, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707833, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856017, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>tf.Tensor(1.7796936, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.0628933, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319165, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707834, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856018, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>tf.Tensor(2.805642, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.0628933, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>tf.Tensor(1.7449969, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.0628933, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>tf.Tensor(1.7753152, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>tf.Tensor(1.6673106, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>tf.Tensor(1.8188568, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>tf.Tensor(1.5375295, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>tf.Tensor(1.7217672, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>tf.Tensor(1.5391448, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>tf.Tensor(1.6540797, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>tf.Tensor(1.7460576, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>tf.Tensor(1.8060933, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>tf.Tensor(1.6248932, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>tf.Tensor(1.6330991, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>tf.Tensor(1.5954661, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>tf.Tensor(1.553469, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>tf.Tensor(1.5998348, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>tf.Tensor(1.5501672, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>tf.Tensor(2.3542838, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>tf.Tensor(1.665332, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(0.010261722, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.10319166, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.32954895, shape=(), dtype=float32)</td>\n",
              "      <td>(tf.Tensor(0.18707836, shape=(), dtype=float32...</td>\n",
              "      <td>tf.Tensor(0.08856019, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5b83586-0595-48aa-b8b8-697680cf8baf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5b83586-0595-48aa-b8b8-697680cf8baf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5b83586-0595-48aa-b8b8-697680cf8baf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e11ba1eb-eda4-4f19-9396-e414adfebdb6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e11ba1eb-eda4-4f19-9396-e414adfebdb6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e11ba1eb-eda4-4f19-9396-e414adfebdb6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"      break\",\n  \"rows\": 28,\n  \"fields\": [\n    {\n      \"column\": \"batch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 28,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          10,\n          26,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IOUMetric\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PerClassIOUMetric\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dice_Coefficent_matrics\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PerClassDiceCoefficientMatrics\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pixel_accurcy_metrics\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h3>📉 Loss Graphs (Batch-wise Trend)</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 16:   8%|▊         | 29/372 [05:49<09:06,  1.59s/it, epoch :16 , batch =0.078]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-49afe2d0c556>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0munet_plus_plus_master_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_unet_plus_plus_for_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_unet_plus_plus_for_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-f890f36cdda9>\u001b[0m in \u001b[0;36mtrain_unet_plus_plus_for_one_epoch\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       }\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0munet_plus_plus_master_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlosss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-dca72b139d61>\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, epoch, data)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-224defb6e4c3>\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, epoch, data)\u001b[0m\n\u001b[1;32m    192\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_table_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_table_display\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, obj, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0madditional\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mupdate_display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \"\"\"\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0mupdate_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mupdate_display\u001b[0;34m(obj, display_id, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \"\"\"\n\u001b[1;32m    349\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'update'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    392\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[0mrepr_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataframe_repr_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrepr_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_html_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, max_cols, show_dimensions, decimal, line_width, min_rows, max_colwidth, encoding)\u001b[0m\n\u001b[1;32m   1392\u001b[0m                 \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m             )\n\u001b[0;32m-> 1394\u001b[0;31m             return fmt.DataFrameRenderer(formatter).to_string(\n\u001b[0m\u001b[1;32m   1395\u001b[0m                 \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self, buf, encoding, line_width)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0mstring_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m         \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msave_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/string.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_string_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_show_dimensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{text}{self.fmt.dimensions_info}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/string.py\u001b[0m in \u001b[0;36m_get_string_representation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_empty_info_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_strcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_width\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/string.py\u001b[0m in \u001b[0;36m_get_strcols\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_strcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_truncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_dot_separators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_strcols\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mRender\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mas\u001b[0m \u001b[0mlists\u001b[0m \u001b[0mof\u001b[0m \u001b[0mstrings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \"\"\"\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mstrcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_strcols_without_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_get_strcols_without_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             )\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m             fmt_values = _make_fixed_width(\n\u001b[1;32m    742\u001b[0m                 \u001b[0mfmt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjustify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_colwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_col\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         return format_array(\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_array\u001b[0;34m(values, formatter, float_format, na_rep, digits, space, justify, decimal, leading_space, quoting, fallback_formatter)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     )\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfmt_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_make_fixed_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjustify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_format_strings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mis_float_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mleading_space\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m                 \u001b[0mfmt_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" {_format(v)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_float_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m                 \u001b[0mfmt_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                 \u001b[0;31m# object dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/printing.py\u001b[0m in \u001b[0;36mpprint_thing\u001b[0;34m(thing, _nest_lvl, escape_chars, default_escapes, quote_strings, max_seq_items)\u001b[0m\n\u001b[1;32m    221\u001b[0m         )\n\u001b[1;32m    222\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_nest_lvl\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.pprint_nest_depth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         result = _pprint_seq(\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0mthing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0m_nest_lvl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/printing.py\u001b[0m in \u001b[0;36m_pprint_seq\u001b[0;34m(seq, _nest_lvl, max_seq_items, **kwds)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# handle sets, no slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     r = [\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mpprint_thing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nest_lvl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/printing.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# handle sets, no slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     r = [\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mpprint_thing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nest_lvl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/printing.py\u001b[0m in \u001b[0;36mpprint_thing\u001b[0;34m(thing, _nest_lvl, escape_chars, default_escapes, quote_strings, max_seq_items)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m def pprint_thing(\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mthing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0m_nest_lvl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  stop_training =False\n",
        "  start=unet_plus_plus_master_callback.on_train_begin()\n",
        "  for epoch in range(start , 250 ):\n",
        "    unet_plus_plus_master_callback.on_epoch_begin(epoch)\n",
        "    losses = train_unet_plus_plus_for_one_epoch(epoch)\n",
        "    val_losses = val_unet_plus_plus_for_one_epoch()\n",
        "    avg_loss = tf.reduce_mean(losses)\n",
        "    avg_val_loss = tf.reduce_mean(val_losses)\n",
        "    data = {\n",
        "\n",
        "                'loss' : avg_loss ,\n",
        "                'val_loss' : avg_val_loss ,\n",
        "                'metrics': {\n",
        "                    'IOUMetric' : unet_plus_plus_IOUMetric.result(),\n",
        "                    'PerClassIOUMetric' : unet_plus_plus_PerClassIOUMetric.result(),\n",
        "                    'Dice_Coefficent_matrics' : unet_plus_plus_Dice_Coefficent_matrics.result(),\n",
        "                    'PerClassDiceCoefficientMatrics' : unet_plus_plus_PerClassDiceCoefficientMatrics.result() ,\n",
        "                    'Pixel_accurcy_metrics' : unet_plus_plus_Pixel_accurcy_metrics.result(),\n",
        "\n",
        "                    'IOUMetric_val' : unet_plus_plus_IOUMetric_val.result(),\n",
        "                    'PerClassIOUMetric_val' : unet_plus_plus_PerClassIOUMetric_val.result(),\n",
        "                    'Dice_Coefficent_matrics_val' : unet_plus_plus_Dice_Coefficent_matrics_val.result(),\n",
        "                    'PerClassDiceCoefficientMatrics_val' : unet_plus_plus_PerClassDiceCoefficientMatrics_val.result() ,\n",
        "                    'Pixel_accurcy_metrics_val' : unet_plus_plus_Pixel_accurcy_metrics_val.result()\n",
        "\n",
        "            },\n",
        "        }\n",
        "    unet_plus_plus_IOUMetric.reset_state()\n",
        "    unet_plus_plus_IOUMetric_val.reset_state()\n",
        "    unet_plus_plus_PerClassIOUMetric.reset_state()\n",
        "    unet_plus_plus_PerClassIOUMetric_val.reset_state()\n",
        "    unet_plus_plus_Dice_Coefficent_matrics.reset_state()\n",
        "    unet_plus_plus_Dice_Coefficent_matrics_val.reset_state()\n",
        "    unet_plus_plus_PerClassDiceCoefficientMatrics.reset_state()\n",
        "    unet_plus_plus_PerClassDiceCoefficientMatrics_val.reset_state()\n",
        "    unet_plus_plus_Pixel_accurcy_metrics.reset_state()\n",
        "    unet_plus_plus_Pixel_accurcy_metrics_val.reset_state()\n",
        "\n",
        "\n",
        "\n",
        "    stop_training=unet_plus_plus_master_callback.on_epoch_end(epoch=epoch , data= data)\n",
        "    if stop_training :\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mp5vqWO_N-C-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}